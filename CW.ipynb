{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"VHDL_model_example\")\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"dataset.csv\", delimiter=\",\")\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(dataset[:,0:8])\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=8, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/80\n",
      "614/614 [==============================] - ETA: 7:47 - loss: 0.6703 - acc: 0.800 - ETA: 1:51 - loss: 0.6877 - acc: 0.675 - ETA: 1:01 - loss: 0.6854 - acc: 0.657 - ETA: 40s - loss: 0.6797 - acc: 0.690 - ETA: 29s - loss: 0.6778 - acc: 0.70 - ETA: 24s - loss: 0.6738 - acc: 0.70 - ETA: 21s - loss: 0.6714 - acc: 0.71 - ETA: 18s - loss: 0.6682 - acc: 0.72 - ETA: 15s - loss: 0.6717 - acc: 0.69 - ETA: 12s - loss: 0.6730 - acc: 0.68 - ETA: 10s - loss: 0.6717 - acc: 0.68 - ETA: 8s - loss: 0.6739 - acc: 0.6733 - ETA: 7s - loss: 0.6749 - acc: 0.669 - ETA: 6s - loss: 0.6767 - acc: 0.660 - ETA: 5s - loss: 0.6797 - acc: 0.647 - ETA: 4s - loss: 0.6814 - acc: 0.639 - ETA: 3s - loss: 0.6816 - acc: 0.636 - ETA: 2s - loss: 0.6824 - acc: 0.634 - ETA: 2s - loss: 0.6816 - acc: 0.636 - ETA: 1s - loss: 0.6807 - acc: 0.639 - ETA: 0s - loss: 0.6793 - acc: 0.642 - ETA: 0s - loss: 0.6773 - acc: 0.650 - 9s 15ms/step - loss: 0.6761 - acc: 0.6515 - val_loss: 0.6693 - val_acc: 0.6429\n",
      "Epoch 2/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6438 - acc: 0.700 - ETA: 1s - loss: 0.6673 - acc: 0.650 - ETA: 1s - loss: 0.6861 - acc: 0.600 - ETA: 1s - loss: 0.6840 - acc: 0.600 - ETA: 0s - loss: 0.6826 - acc: 0.607 - ETA: 0s - loss: 0.6827 - acc: 0.606 - ETA: 0s - loss: 0.6832 - acc: 0.605 - ETA: 0s - loss: 0.6802 - acc: 0.613 - ETA: 0s - loss: 0.6801 - acc: 0.612 - ETA: 0s - loss: 0.6745 - acc: 0.628 - ETA: 0s - loss: 0.6705 - acc: 0.638 - ETA: 0s - loss: 0.6699 - acc: 0.638 - ETA: 0s - loss: 0.6715 - acc: 0.632 - ETA: 0s - loss: 0.6683 - acc: 0.640 - ETA: 0s - loss: 0.6680 - acc: 0.639 - ETA: 0s - loss: 0.6661 - acc: 0.644 - ETA: 0s - loss: 0.6667 - acc: 0.643 - ETA: 0s - loss: 0.6678 - acc: 0.643 - ETA: 0s - loss: 0.6668 - acc: 0.646 - ETA: 0s - loss: 0.6658 - acc: 0.650 - ETA: 0s - loss: 0.6658 - acc: 0.650 - 1s 2ms/step - loss: 0.6649 - acc: 0.6531 - val_loss: 0.6630 - val_acc: 0.6429\n",
      "Epoch 3/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6570 - acc: 0.600 - ETA: 0s - loss: 0.6764 - acc: 0.600 - ETA: 0s - loss: 0.6710 - acc: 0.628 - ETA: 0s - loss: 0.6667 - acc: 0.640 - ETA: 0s - loss: 0.6687 - acc: 0.638 - ETA: 0s - loss: 0.6732 - acc: 0.625 - ETA: 0s - loss: 0.6721 - acc: 0.626 - ETA: 0s - loss: 0.6626 - acc: 0.650 - ETA: 0s - loss: 0.6627 - acc: 0.648 - ETA: 0s - loss: 0.6618 - acc: 0.650 - ETA: 0s - loss: 0.6635 - acc: 0.645 - ETA: 0s - loss: 0.6625 - acc: 0.647 - ETA: 0s - loss: 0.6654 - acc: 0.640 - ETA: 0s - loss: 0.6663 - acc: 0.640 - ETA: 0s - loss: 0.6634 - acc: 0.647 - ETA: 0s - loss: 0.6651 - acc: 0.642 - ETA: 0s - loss: 0.6641 - acc: 0.644 - ETA: 0s - loss: 0.6616 - acc: 0.651 - ETA: 0s - loss: 0.6593 - acc: 0.653 - ETA: 0s - loss: 0.6627 - acc: 0.645 - ETA: 0s - loss: 0.6633 - acc: 0.643 - ETA: 0s - loss: 0.6588 - acc: 0.654 - 1s 2ms/step - loss: 0.6590 - acc: 0.6531 - val_loss: 0.6581 - val_acc: 0.6429\n",
      "Epoch 4/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6606 - acc: 0.600 - ETA: 1s - loss: 0.6614 - acc: 0.625 - ETA: 1s - loss: 0.6740 - acc: 0.600 - ETA: 1s - loss: 0.6641 - acc: 0.630 - ETA: 1s - loss: 0.6639 - acc: 0.633 - ETA: 1s - loss: 0.6647 - acc: 0.628 - ETA: 0s - loss: 0.6526 - acc: 0.652 - ETA: 0s - loss: 0.6597 - acc: 0.640 - ETA: 0s - loss: 0.6588 - acc: 0.645 - ETA: 0s - loss: 0.6613 - acc: 0.640 - ETA: 0s - loss: 0.6630 - acc: 0.635 - ETA: 0s - loss: 0.6588 - acc: 0.646 - ETA: 0s - loss: 0.6534 - acc: 0.659 - ETA: 0s - loss: 0.6540 - acc: 0.657 - ETA: 0s - loss: 0.6550 - acc: 0.652 - ETA: 0s - loss: 0.6565 - acc: 0.648 - ETA: 0s - loss: 0.6590 - acc: 0.643 - ETA: 0s - loss: 0.6570 - acc: 0.646 - ETA: 0s - loss: 0.6585 - acc: 0.642 - ETA: 0s - loss: 0.6574 - acc: 0.645 - ETA: 0s - loss: 0.6541 - acc: 0.651 - ETA: 0s - loss: 0.6537 - acc: 0.654 - 1s 2ms/step - loss: 0.6544 - acc: 0.6531 - val_loss: 0.6542 - val_acc: 0.6429\n",
      "Epoch 5/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6212 - acc: 0.700 - ETA: 0s - loss: 0.6500 - acc: 0.660 - ETA: 0s - loss: 0.6685 - acc: 0.612 - ETA: 0s - loss: 0.6589 - acc: 0.636 - ETA: 0s - loss: 0.6594 - acc: 0.635 - ETA: 0s - loss: 0.6613 - acc: 0.629 - ETA: 0s - loss: 0.6620 - acc: 0.630 - ETA: 0s - loss: 0.6520 - acc: 0.652 - ETA: 0s - loss: 0.6511 - acc: 0.653 - ETA: 0s - loss: 0.6472 - acc: 0.658 - ETA: 0s - loss: 0.6444 - acc: 0.666 - ETA: 0s - loss: 0.6499 - acc: 0.655 - ETA: 0s - loss: 0.6501 - acc: 0.656 - ETA: 0s - loss: 0.6479 - acc: 0.661 - ETA: 0s - loss: 0.6471 - acc: 0.665 - ETA: 0s - loss: 0.6477 - acc: 0.663 - ETA: 0s - loss: 0.6464 - acc: 0.665 - ETA: 0s - loss: 0.6494 - acc: 0.657 - ETA: 0s - loss: 0.6513 - acc: 0.652 - ETA: 0s - loss: 0.6507 - acc: 0.652 - 1s 2ms/step - loss: 0.6505 - acc: 0.6531 - val_loss: 0.6504 - val_acc: 0.6429\n",
      "Epoch 6/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5793 - acc: 0.800 - ETA: 0s - loss: 0.6203 - acc: 0.700 - ETA: 0s - loss: 0.6366 - acc: 0.671 - ETA: 0s - loss: 0.6451 - acc: 0.660 - ETA: 0s - loss: 0.6315 - acc: 0.684 - ETA: 0s - loss: 0.6319 - acc: 0.687 - ETA: 0s - loss: 0.6334 - acc: 0.684 - ETA: 0s - loss: 0.6401 - acc: 0.669 - ETA: 0s - loss: 0.6489 - acc: 0.650 - ETA: 0s - loss: 0.6566 - acc: 0.634 - ETA: 0s - loss: 0.6577 - acc: 0.631 - ETA: 0s - loss: 0.6540 - acc: 0.637 - ETA: 0s - loss: 0.6524 - acc: 0.639 - ETA: 0s - loss: 0.6507 - acc: 0.643 - ETA: 0s - loss: 0.6469 - acc: 0.652 - ETA: 0s - loss: 0.6490 - acc: 0.647 - ETA: 0s - loss: 0.6496 - acc: 0.644 - ETA: 0s - loss: 0.6474 - acc: 0.649 - ETA: 0s - loss: 0.6459 - acc: 0.651 - ETA: 0s - loss: 0.6448 - acc: 0.654 - ETA: 0s - loss: 0.6441 - acc: 0.656 - 1s 2ms/step - loss: 0.6465 - acc: 0.6531 - val_loss: 0.6464 - val_acc: 0.6429\n",
      "Epoch 7/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5193 - acc: 0.900 - ETA: 1s - loss: 0.6313 - acc: 0.675 - ETA: 1s - loss: 0.6206 - acc: 0.700 - ETA: 0s - loss: 0.6281 - acc: 0.700 - ETA: 0s - loss: 0.6190 - acc: 0.715 - ETA: 0s - loss: 0.6348 - acc: 0.681 - ETA: 0s - loss: 0.6340 - acc: 0.678 - ETA: 0s - loss: 0.6291 - acc: 0.685 - ETA: 0s - loss: 0.6280 - acc: 0.683 - ETA: 0s - loss: 0.6310 - acc: 0.674 - ETA: 0s - loss: 0.6383 - acc: 0.661 - ETA: 0s - loss: 0.6355 - acc: 0.667 - ETA: 0s - loss: 0.6385 - acc: 0.663 - ETA: 0s - loss: 0.6417 - acc: 0.657 - ETA: 0s - loss: 0.6448 - acc: 0.651 - ETA: 0s - loss: 0.6453 - acc: 0.647 - ETA: 0s - loss: 0.6459 - acc: 0.647 - ETA: 0s - loss: 0.6434 - acc: 0.650 - ETA: 0s - loss: 0.6424 - acc: 0.650 - ETA: 0s - loss: 0.6416 - acc: 0.653 - 1s 2ms/step - loss: 0.6419 - acc: 0.6531 - val_loss: 0.6425 - val_acc: 0.6429\n",
      "Epoch 8/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5656 - acc: 0.800 - ETA: 0s - loss: 0.6168 - acc: 0.700 - ETA: 0s - loss: 0.6586 - acc: 0.600 - ETA: 0s - loss: 0.6521 - acc: 0.616 - ETA: 0s - loss: 0.6425 - acc: 0.643 - ETA: 0s - loss: 0.6437 - acc: 0.638 - ETA: 0s - loss: 0.6446 - acc: 0.638 - ETA: 0s - loss: 0.6451 - acc: 0.637 - ETA: 0s - loss: 0.6419 - acc: 0.640 - ETA: 0s - loss: 0.6372 - acc: 0.653 - ETA: 0s - loss: 0.6386 - acc: 0.648 - ETA: 0s - loss: 0.6394 - acc: 0.647 - ETA: 0s - loss: 0.6438 - acc: 0.638 - ETA: 0s - loss: 0.6426 - acc: 0.640 - ETA: 0s - loss: 0.6416 - acc: 0.642 - ETA: 0s - loss: 0.6427 - acc: 0.637 - ETA: 0s - loss: 0.6441 - acc: 0.635 - ETA: 0s - loss: 0.6405 - acc: 0.642 - ETA: 0s - loss: 0.6407 - acc: 0.643 - ETA: 0s - loss: 0.6367 - acc: 0.653 - 1s 2ms/step - loss: 0.6374 - acc: 0.6515 - val_loss: 0.6379 - val_acc: 0.6429\n",
      "Epoch 9/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6364 - acc: 0.600 - ETA: 0s - loss: 0.6319 - acc: 0.640 - ETA: 0s - loss: 0.6398 - acc: 0.637 - ETA: 0s - loss: 0.6474 - acc: 0.636 - ETA: 0s - loss: 0.6608 - acc: 0.607 - ETA: 0s - loss: 0.6479 - acc: 0.629 - ETA: 0s - loss: 0.6557 - acc: 0.610 - ETA: 0s - loss: 0.6447 - acc: 0.633 - ETA: 0s - loss: 0.6451 - acc: 0.629 - ETA: 0s - loss: 0.6419 - acc: 0.636 - ETA: 0s - loss: 0.6390 - acc: 0.645 - ETA: 0s - loss: 0.6377 - acc: 0.648 - ETA: 0s - loss: 0.6304 - acc: 0.663 - ETA: 0s - loss: 0.6271 - acc: 0.668 - ETA: 0s - loss: 0.6249 - acc: 0.671 - ETA: 0s - loss: 0.6276 - acc: 0.665 - ETA: 0s - loss: 0.6283 - acc: 0.663 - ETA: 0s - loss: 0.6291 - acc: 0.660 - ETA: 0s - loss: 0.6284 - acc: 0.662 - 1s 2ms/step - loss: 0.6328 - acc: 0.6531 - val_loss: 0.6338 - val_acc: 0.6429\n",
      "Epoch 10/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6287 - acc: 0.600 - ETA: 0s - loss: 0.5851 - acc: 0.700 - ETA: 0s - loss: 0.6268 - acc: 0.650 - ETA: 0s - loss: 0.6082 - acc: 0.690 - ETA: 0s - loss: 0.6160 - acc: 0.678 - ETA: 0s - loss: 0.6203 - acc: 0.670 - ETA: 0s - loss: 0.6298 - acc: 0.645 - ETA: 0s - loss: 0.6228 - acc: 0.660 - ETA: 0s - loss: 0.6179 - acc: 0.669 - ETA: 0s - loss: 0.6303 - acc: 0.648 - ETA: 0s - loss: 0.6289 - acc: 0.653 - ETA: 0s - loss: 0.6232 - acc: 0.665 - ETA: 0s - loss: 0.6204 - acc: 0.668 - ETA: 0s - loss: 0.6225 - acc: 0.665 - ETA: 0s - loss: 0.6230 - acc: 0.668 - ETA: 0s - loss: 0.6247 - acc: 0.663 - ETA: 0s - loss: 0.6246 - acc: 0.661 - ETA: 0s - loss: 0.6217 - acc: 0.665 - ETA: 0s - loss: 0.6236 - acc: 0.661 - ETA: 0s - loss: 0.6242 - acc: 0.662 - ETA: 0s - loss: 0.6264 - acc: 0.657 - 1s 2ms/step - loss: 0.6272 - acc: 0.6564 - val_loss: 0.6285 - val_acc: 0.6429\n",
      "Epoch 11/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.7019 - acc: 0.500 - ETA: 1s - loss: 0.6351 - acc: 0.600 - ETA: 1s - loss: 0.6382 - acc: 0.628 - ETA: 0s - loss: 0.6547 - acc: 0.590 - ETA: 0s - loss: 0.6414 - acc: 0.607 - ETA: 0s - loss: 0.6362 - acc: 0.618 - ETA: 0s - loss: 0.6294 - acc: 0.631 - ETA: 0s - loss: 0.6215 - acc: 0.650 - ETA: 0s - loss: 0.6253 - acc: 0.650 - ETA: 0s - loss: 0.6242 - acc: 0.648 - ETA: 0s - loss: 0.6228 - acc: 0.653 - ETA: 0s - loss: 0.6237 - acc: 0.648 - ETA: 0s - loss: 0.6263 - acc: 0.644 - ETA: 0s - loss: 0.6295 - acc: 0.641 - ETA: 0s - loss: 0.6288 - acc: 0.642 - ETA: 0s - loss: 0.6280 - acc: 0.647 - ETA: 0s - loss: 0.6273 - acc: 0.650 - ETA: 0s - loss: 0.6260 - acc: 0.650 - ETA: 0s - loss: 0.6238 - acc: 0.656 - ETA: 0s - loss: 0.6230 - acc: 0.660 - 1s 2ms/step - loss: 0.6224 - acc: 0.6612 - val_loss: 0.6230 - val_acc: 0.6429\n",
      "Epoch 12/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.8245 - acc: 0.400 - ETA: 0s - loss: 0.6473 - acc: 0.620 - ETA: 0s - loss: 0.6331 - acc: 0.625 - ETA: 0s - loss: 0.6100 - acc: 0.675 - ETA: 0s - loss: 0.6134 - acc: 0.673 - ETA: 0s - loss: 0.6129 - acc: 0.673 - ETA: 0s - loss: 0.6289 - acc: 0.650 - ETA: 0s - loss: 0.6181 - acc: 0.668 - ETA: 0s - loss: 0.6263 - acc: 0.653 - ETA: 0s - loss: 0.6221 - acc: 0.664 - ETA: 0s - loss: 0.6193 - acc: 0.673 - ETA: 0s - loss: 0.6135 - acc: 0.673 - ETA: 0s - loss: 0.6188 - acc: 0.665 - ETA: 0s - loss: 0.6193 - acc: 0.662 - ETA: 0s - loss: 0.6202 - acc: 0.658 - ETA: 0s - loss: 0.6149 - acc: 0.666 - ETA: 0s - loss: 0.6156 - acc: 0.666 - ETA: 0s - loss: 0.6175 - acc: 0.662 - 1s 2ms/step - loss: 0.6165 - acc: 0.6629 - val_loss: 0.6177 - val_acc: 0.6494\n",
      "Epoch 13/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6095 - acc: 0.800 - ETA: 0s - loss: 0.6098 - acc: 0.700 - ETA: 1s - loss: 0.6176 - acc: 0.657 - ETA: 0s - loss: 0.6219 - acc: 0.660 - ETA: 0s - loss: 0.6363 - acc: 0.630 - ETA: 0s - loss: 0.6277 - acc: 0.643 - ETA: 0s - loss: 0.6299 - acc: 0.638 - ETA: 0s - loss: 0.6228 - acc: 0.657 - ETA: 0s - loss: 0.6156 - acc: 0.679 - ETA: 0s - loss: 0.6122 - acc: 0.681 - ETA: 0s - loss: 0.6187 - acc: 0.660 - ETA: 0s - loss: 0.6231 - acc: 0.651 - ETA: 0s - loss: 0.6353 - acc: 0.625 - ETA: 0s - loss: 0.6330 - acc: 0.633 - ETA: 0s - loss: 0.6273 - acc: 0.645 - ETA: 0s - loss: 0.6212 - acc: 0.655 - ETA: 0s - loss: 0.6172 - acc: 0.664 - ETA: 0s - loss: 0.6186 - acc: 0.660 - ETA: 0s - loss: 0.6182 - acc: 0.657 - ETA: 0s - loss: 0.6102 - acc: 0.670 - ETA: 0s - loss: 0.6122 - acc: 0.668 - 1s 2ms/step - loss: 0.6120 - acc: 0.6710 - val_loss: 0.6117 - val_acc: 0.6429\n",
      "Epoch 14/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5836 - acc: 0.700 - ETA: 0s - loss: 0.6050 - acc: 0.640 - ETA: 0s - loss: 0.6103 - acc: 0.650 - ETA: 0s - loss: 0.5963 - acc: 0.680 - ETA: 0s - loss: 0.6120 - acc: 0.653 - ETA: 0s - loss: 0.6119 - acc: 0.643 - ETA: 0s - loss: 0.6065 - acc: 0.663 - ETA: 0s - loss: 0.6059 - acc: 0.665 - ETA: 0s - loss: 0.5978 - acc: 0.681 - ETA: 0s - loss: 0.6057 - acc: 0.670 - ETA: 0s - loss: 0.6035 - acc: 0.675 - ETA: 0s - loss: 0.5992 - acc: 0.686 - ETA: 0s - loss: 0.5962 - acc: 0.690 - ETA: 0s - loss: 0.5998 - acc: 0.683 - ETA: 0s - loss: 0.6027 - acc: 0.680 - ETA: 0s - loss: 0.6019 - acc: 0.677 - ETA: 0s - loss: 0.6018 - acc: 0.676 - ETA: 0s - loss: 0.6047 - acc: 0.674 - ETA: 0s - loss: 0.6032 - acc: 0.674 - 1s 2ms/step - loss: 0.6058 - acc: 0.6710 - val_loss: 0.6064 - val_acc: 0.6429\n",
      "Epoch 15/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6393 - acc: 0.500 - ETA: 0s - loss: 0.6007 - acc: 0.660 - ETA: 0s - loss: 0.6291 - acc: 0.612 - ETA: 0s - loss: 0.6632 - acc: 0.541 - ETA: 0s - loss: 0.6369 - acc: 0.606 - ETA: 0s - loss: 0.6287 - acc: 0.626 - ETA: 0s - loss: 0.6243 - acc: 0.640 - ETA: 0s - loss: 0.6145 - acc: 0.652 - ETA: 0s - loss: 0.6142 - acc: 0.658 - ETA: 0s - loss: 0.6116 - acc: 0.665 - ETA: 0s - loss: 0.6099 - acc: 0.665 - ETA: 0s - loss: 0.6067 - acc: 0.671 - ETA: 0s - loss: 0.6023 - acc: 0.685 - ETA: 0s - loss: 0.6019 - acc: 0.684 - ETA: 0s - loss: 0.5975 - acc: 0.693 - ETA: 0s - loss: 0.6016 - acc: 0.686 - ETA: 0s - loss: 0.6055 - acc: 0.678 - ETA: 0s - loss: 0.6026 - acc: 0.684 - 1s 2ms/step - loss: 0.6003 - acc: 0.6873 - val_loss: 0.6004 - val_acc: 0.6429\n",
      "Epoch 16/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5147 - acc: 0.900 - ETA: 1s - loss: 0.5454 - acc: 0.800 - ETA: 1s - loss: 0.5583 - acc: 0.771 - ETA: 0s - loss: 0.5856 - acc: 0.740 - ETA: 0s - loss: 0.5829 - acc: 0.715 - ETA: 0s - loss: 0.5896 - acc: 0.700 - ETA: 0s - loss: 0.5786 - acc: 0.710 - ETA: 0s - loss: 0.5855 - acc: 0.700 - ETA: 0s - loss: 0.5818 - acc: 0.707 - ETA: 0s - loss: 0.5758 - acc: 0.713 - ETA: 0s - loss: 0.5782 - acc: 0.709 - ETA: 0s - loss: 0.5867 - acc: 0.697 - ETA: 0s - loss: 0.5915 - acc: 0.690 - ETA: 0s - loss: 0.5914 - acc: 0.688 - ETA: 0s - loss: 0.5913 - acc: 0.689 - ETA: 0s - loss: 0.5926 - acc: 0.690 - ETA: 0s - loss: 0.5960 - acc: 0.687 - ETA: 0s - loss: 0.5950 - acc: 0.681 - 1s 2ms/step - loss: 0.5939 - acc: 0.6824 - val_loss: 0.5937 - val_acc: 0.6494\n",
      "Epoch 17/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5760 - acc: 0.700 - ETA: 0s - loss: 0.5912 - acc: 0.680 - ETA: 0s - loss: 0.5714 - acc: 0.711 - ETA: 0s - loss: 0.5677 - acc: 0.741 - ETA: 0s - loss: 0.5579 - acc: 0.750 - ETA: 0s - loss: 0.5704 - acc: 0.726 - ETA: 0s - loss: 0.5779 - acc: 0.704 - ETA: 0s - loss: 0.5912 - acc: 0.688 - ETA: 0s - loss: 0.5896 - acc: 0.689 - ETA: 0s - loss: 0.5801 - acc: 0.700 - ETA: 0s - loss: 0.5790 - acc: 0.702 - ETA: 0s - loss: 0.5799 - acc: 0.697 - ETA: 0s - loss: 0.5768 - acc: 0.705 - ETA: 0s - loss: 0.5786 - acc: 0.700 - ETA: 0s - loss: 0.5791 - acc: 0.700 - ETA: 0s - loss: 0.5788 - acc: 0.707 - ETA: 0s - loss: 0.5855 - acc: 0.698 - ETA: 0s - loss: 0.5878 - acc: 0.694 - ETA: 0s - loss: 0.5889 - acc: 0.693 - 1s 2ms/step - loss: 0.5881 - acc: 0.6954 - val_loss: 0.5868 - val_acc: 0.6558\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - ETA: 0s - loss: 0.5700 - acc: 0.600 - ETA: 0s - loss: 0.5918 - acc: 0.660 - ETA: 0s - loss: 0.5746 - acc: 0.687 - ETA: 0s - loss: 0.5448 - acc: 0.745 - ETA: 0s - loss: 0.5458 - acc: 0.746 - ETA: 0s - loss: 0.5301 - acc: 0.756 - ETA: 0s - loss: 0.5493 - acc: 0.731 - ETA: 0s - loss: 0.5558 - acc: 0.731 - ETA: 0s - loss: 0.5710 - acc: 0.712 - ETA: 0s - loss: 0.5755 - acc: 0.703 - ETA: 0s - loss: 0.5752 - acc: 0.712 - ETA: 0s - loss: 0.5694 - acc: 0.722 - ETA: 0s - loss: 0.5657 - acc: 0.728 - ETA: 0s - loss: 0.5755 - acc: 0.714 - ETA: 0s - loss: 0.5760 - acc: 0.711 - ETA: 0s - loss: 0.5796 - acc: 0.706 - ETA: 0s - loss: 0.5846 - acc: 0.698 - ETA: 0s - loss: 0.5854 - acc: 0.700 - ETA: 0s - loss: 0.5827 - acc: 0.698 - ETA: 0s - loss: 0.5807 - acc: 0.701 - 1s 2ms/step - loss: 0.5822 - acc: 0.7003 - val_loss: 0.5799 - val_acc: 0.6688\n",
      "Epoch 19/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6040 - acc: 0.700 - ETA: 1s - loss: 0.6311 - acc: 0.675 - ETA: 0s - loss: 0.5907 - acc: 0.728 - ETA: 0s - loss: 0.5827 - acc: 0.709 - ETA: 0s - loss: 0.6088 - acc: 0.671 - ETA: 0s - loss: 0.6068 - acc: 0.677 - ETA: 0s - loss: 0.6027 - acc: 0.666 - ETA: 0s - loss: 0.6033 - acc: 0.656 - ETA: 0s - loss: 0.6025 - acc: 0.669 - ETA: 0s - loss: 0.6000 - acc: 0.671 - ETA: 0s - loss: 0.5884 - acc: 0.694 - ETA: 0s - loss: 0.5817 - acc: 0.705 - ETA: 0s - loss: 0.5830 - acc: 0.704 - ETA: 0s - loss: 0.5865 - acc: 0.697 - ETA: 0s - loss: 0.5825 - acc: 0.704 - ETA: 0s - loss: 0.5834 - acc: 0.700 - ETA: 0s - loss: 0.5835 - acc: 0.700 - ETA: 0s - loss: 0.5803 - acc: 0.701 - ETA: 0s - loss: 0.5792 - acc: 0.705 - 1s 2ms/step - loss: 0.5767 - acc: 0.7085 - val_loss: 0.5749 - val_acc: 0.6688\n",
      "Epoch 20/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5337 - acc: 0.800 - ETA: 1s - loss: 0.5426 - acc: 0.700 - ETA: 0s - loss: 0.5287 - acc: 0.757 - ETA: 0s - loss: 0.5634 - acc: 0.730 - ETA: 0s - loss: 0.5674 - acc: 0.715 - ETA: 0s - loss: 0.5840 - acc: 0.687 - ETA: 0s - loss: 0.5698 - acc: 0.700 - ETA: 0s - loss: 0.5755 - acc: 0.700 - ETA: 0s - loss: 0.5669 - acc: 0.712 - ETA: 0s - loss: 0.5744 - acc: 0.703 - ETA: 0s - loss: 0.5735 - acc: 0.703 - ETA: 0s - loss: 0.5715 - acc: 0.705 - ETA: 0s - loss: 0.5690 - acc: 0.713 - ETA: 0s - loss: 0.5684 - acc: 0.717 - ETA: 0s - loss: 0.5689 - acc: 0.713 - ETA: 0s - loss: 0.5686 - acc: 0.712 - ETA: 0s - loss: 0.5674 - acc: 0.716 - ETA: 0s - loss: 0.5677 - acc: 0.713 - ETA: 0s - loss: 0.5725 - acc: 0.710 - ETA: 0s - loss: 0.5751 - acc: 0.703 - ETA: 0s - loss: 0.5716 - acc: 0.711 - 1s 2ms/step - loss: 0.5706 - acc: 0.7150 - val_loss: 0.5679 - val_acc: 0.6883\n",
      "Epoch 21/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5311 - acc: 0.700 - ETA: 1s - loss: 0.5448 - acc: 0.750 - ETA: 1s - loss: 0.5532 - acc: 0.742 - ETA: 1s - loss: 0.5927 - acc: 0.690 - ETA: 0s - loss: 0.5932 - acc: 0.692 - ETA: 0s - loss: 0.5800 - acc: 0.712 - ETA: 0s - loss: 0.5794 - acc: 0.710 - ETA: 0s - loss: 0.5749 - acc: 0.713 - ETA: 0s - loss: 0.5737 - acc: 0.716 - ETA: 0s - loss: 0.5826 - acc: 0.692 - ETA: 0s - loss: 0.5813 - acc: 0.693 - ETA: 0s - loss: 0.5809 - acc: 0.697 - ETA: 0s - loss: 0.5819 - acc: 0.700 - ETA: 0s - loss: 0.5808 - acc: 0.700 - ETA: 0s - loss: 0.5741 - acc: 0.711 - ETA: 0s - loss: 0.5713 - acc: 0.713 - ETA: 0s - loss: 0.5721 - acc: 0.714 - ETA: 0s - loss: 0.5686 - acc: 0.719 - ETA: 0s - loss: 0.5655 - acc: 0.723 - ETA: 0s - loss: 0.5647 - acc: 0.724 - ETA: 0s - loss: 0.5641 - acc: 0.724 - 1s 2ms/step - loss: 0.5645 - acc: 0.7248 - val_loss: 0.5634 - val_acc: 0.6948\n",
      "Epoch 22/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3598 - acc: 1.000 - ETA: 1s - loss: 0.5042 - acc: 0.775 - ETA: 0s - loss: 0.5379 - acc: 0.742 - ETA: 0s - loss: 0.5744 - acc: 0.710 - ETA: 0s - loss: 0.5653 - acc: 0.730 - ETA: 0s - loss: 0.5439 - acc: 0.756 - ETA: 0s - loss: 0.5472 - acc: 0.761 - ETA: 0s - loss: 0.5586 - acc: 0.752 - ETA: 0s - loss: 0.5610 - acc: 0.745 - ETA: 0s - loss: 0.5572 - acc: 0.751 - ETA: 0s - loss: 0.5527 - acc: 0.756 - ETA: 0s - loss: 0.5513 - acc: 0.757 - ETA: 0s - loss: 0.5474 - acc: 0.766 - ETA: 0s - loss: 0.5464 - acc: 0.761 - ETA: 0s - loss: 0.5443 - acc: 0.759 - ETA: 0s - loss: 0.5546 - acc: 0.746 - ETA: 0s - loss: 0.5584 - acc: 0.740 - ETA: 0s - loss: 0.5607 - acc: 0.734 - ETA: 0s - loss: 0.5598 - acc: 0.732 - ETA: 0s - loss: 0.5596 - acc: 0.731 - ETA: 0s - loss: 0.5570 - acc: 0.734 - 1s 2ms/step - loss: 0.5569 - acc: 0.7345 - val_loss: 0.5585 - val_acc: 0.7013\n",
      "Epoch 23/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4390 - acc: 0.900 - ETA: 1s - loss: 0.6371 - acc: 0.600 - ETA: 1s - loss: 0.6059 - acc: 0.666 - ETA: 1s - loss: 0.6127 - acc: 0.666 - ETA: 1s - loss: 0.5886 - acc: 0.666 - ETA: 0s - loss: 0.5810 - acc: 0.686 - ETA: 0s - loss: 0.5908 - acc: 0.683 - ETA: 0s - loss: 0.5889 - acc: 0.685 - ETA: 0s - loss: 0.5819 - acc: 0.687 - ETA: 0s - loss: 0.5784 - acc: 0.688 - ETA: 0s - loss: 0.5777 - acc: 0.700 - ETA: 0s - loss: 0.5689 - acc: 0.703 - ETA: 0s - loss: 0.5646 - acc: 0.713 - ETA: 0s - loss: 0.5647 - acc: 0.712 - ETA: 0s - loss: 0.5609 - acc: 0.723 - ETA: 0s - loss: 0.5640 - acc: 0.717 - ETA: 0s - loss: 0.5613 - acc: 0.726 - ETA: 0s - loss: 0.5589 - acc: 0.728 - ETA: 0s - loss: 0.5577 - acc: 0.727 - ETA: 0s - loss: 0.5537 - acc: 0.735 - ETA: 0s - loss: 0.5512 - acc: 0.743 - 1s 2ms/step - loss: 0.5505 - acc: 0.7427 - val_loss: 0.5520 - val_acc: 0.7143\n",
      "Epoch 24/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5537 - acc: 0.700 - ETA: 1s - loss: 0.4834 - acc: 0.800 - ETA: 0s - loss: 0.5248 - acc: 0.757 - ETA: 0s - loss: 0.5678 - acc: 0.700 - ETA: 0s - loss: 0.5699 - acc: 0.700 - ETA: 0s - loss: 0.5663 - acc: 0.706 - ETA: 0s - loss: 0.5680 - acc: 0.705 - ETA: 0s - loss: 0.5721 - acc: 0.700 - ETA: 0s - loss: 0.5709 - acc: 0.708 - ETA: 0s - loss: 0.5557 - acc: 0.721 - ETA: 0s - loss: 0.5509 - acc: 0.729 - ETA: 0s - loss: 0.5514 - acc: 0.729 - ETA: 0s - loss: 0.5482 - acc: 0.732 - ETA: 0s - loss: 0.5439 - acc: 0.740 - ETA: 0s - loss: 0.5465 - acc: 0.734 - ETA: 0s - loss: 0.5442 - acc: 0.741 - ETA: 0s - loss: 0.5417 - acc: 0.744 - ETA: 0s - loss: 0.5417 - acc: 0.746 - ETA: 0s - loss: 0.5450 - acc: 0.743 - ETA: 0s - loss: 0.5456 - acc: 0.743 - ETA: 0s - loss: 0.5471 - acc: 0.739 - 1s 2ms/step - loss: 0.5456 - acc: 0.7410 - val_loss: 0.5478 - val_acc: 0.7078\n",
      "Epoch 25/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5035 - acc: 0.900 - ETA: 0s - loss: 0.5178 - acc: 0.800 - ETA: 0s - loss: 0.5731 - acc: 0.757 - ETA: 0s - loss: 0.5810 - acc: 0.720 - ETA: 0s - loss: 0.5810 - acc: 0.707 - ETA: 0s - loss: 0.5773 - acc: 0.700 - ETA: 0s - loss: 0.5573 - acc: 0.715 - ETA: 0s - loss: 0.5481 - acc: 0.718 - ETA: 0s - loss: 0.5397 - acc: 0.728 - ETA: 0s - loss: 0.5435 - acc: 0.729 - ETA: 0s - loss: 0.5336 - acc: 0.746 - ETA: 0s - loss: 0.5361 - acc: 0.738 - ETA: 0s - loss: 0.5359 - acc: 0.740 - ETA: 0s - loss: 0.5286 - acc: 0.747 - ETA: 0s - loss: 0.5318 - acc: 0.737 - ETA: 0s - loss: 0.5315 - acc: 0.737 - ETA: 0s - loss: 0.5328 - acc: 0.734 - ETA: 0s - loss: 0.5362 - acc: 0.732 - ETA: 0s - loss: 0.5348 - acc: 0.736 - ETA: 0s - loss: 0.5404 - acc: 0.732 - ETA: 0s - loss: 0.5405 - acc: 0.734 - 1s 2ms/step - loss: 0.5403 - acc: 0.7345 - val_loss: 0.5425 - val_acc: 0.7078\n",
      "Epoch 26/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6922 - acc: 0.500 - ETA: 1s - loss: 0.5542 - acc: 0.750 - ETA: 0s - loss: 0.5691 - acc: 0.714 - ETA: 0s - loss: 0.5875 - acc: 0.680 - ETA: 0s - loss: 0.5911 - acc: 0.691 - ETA: 0s - loss: 0.5879 - acc: 0.706 - ETA: 0s - loss: 0.5773 - acc: 0.715 - ETA: 0s - loss: 0.5728 - acc: 0.718 - ETA: 0s - loss: 0.5616 - acc: 0.724 - ETA: 0s - loss: 0.5650 - acc: 0.717 - ETA: 0s - loss: 0.5542 - acc: 0.725 - ETA: 0s - loss: 0.5425 - acc: 0.735 - ETA: 0s - loss: 0.5355 - acc: 0.740 - ETA: 0s - loss: 0.5310 - acc: 0.750 - ETA: 0s - loss: 0.5310 - acc: 0.751 - ETA: 0s - loss: 0.5361 - acc: 0.747 - ETA: 0s - loss: 0.5371 - acc: 0.746 - ETA: 0s - loss: 0.5380 - acc: 0.746 - ETA: 0s - loss: 0.5380 - acc: 0.747 - ETA: 0s - loss: 0.5402 - acc: 0.743 - ETA: 0s - loss: 0.5382 - acc: 0.744 - 1s 2ms/step - loss: 0.5379 - acc: 0.7427 - val_loss: 0.5347 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5201 - acc: 0.700 - ETA: 1s - loss: 0.6222 - acc: 0.625 - ETA: 1s - loss: 0.5904 - acc: 0.700 - ETA: 1s - loss: 0.5866 - acc: 0.677 - ETA: 1s - loss: 0.5885 - acc: 0.666 - ETA: 0s - loss: 0.5899 - acc: 0.686 - ETA: 0s - loss: 0.5716 - acc: 0.711 - ETA: 0s - loss: 0.5574 - acc: 0.714 - ETA: 0s - loss: 0.5587 - acc: 0.708 - ETA: 0s - loss: 0.5509 - acc: 0.722 - ETA: 0s - loss: 0.5478 - acc: 0.732 - ETA: 0s - loss: 0.5424 - acc: 0.742 - ETA: 0s - loss: 0.5350 - acc: 0.746 - ETA: 0s - loss: 0.5341 - acc: 0.741 - ETA: 0s - loss: 0.5366 - acc: 0.741 - ETA: 0s - loss: 0.5320 - acc: 0.744 - ETA: 0s - loss: 0.5263 - acc: 0.751 - ETA: 0s - loss: 0.5356 - acc: 0.740 - ETA: 0s - loss: 0.5367 - acc: 0.743 - ETA: 0s - loss: 0.5336 - acc: 0.749 - 1s 2ms/step - loss: 0.5319 - acc: 0.7508 - val_loss: 0.5312 - val_acc: 0.7208\n",
      "Epoch 28/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5699 - acc: 0.600 - ETA: 1s - loss: 0.4965 - acc: 0.775 - ETA: 1s - loss: 0.5130 - acc: 0.757 - ETA: 0s - loss: 0.5206 - acc: 0.760 - ETA: 0s - loss: 0.4976 - acc: 0.776 - ETA: 0s - loss: 0.5137 - acc: 0.756 - ETA: 0s - loss: 0.5389 - acc: 0.726 - ETA: 0s - loss: 0.5327 - acc: 0.740 - ETA: 0s - loss: 0.5239 - acc: 0.744 - ETA: 0s - loss: 0.5107 - acc: 0.753 - ETA: 0s - loss: 0.5116 - acc: 0.758 - ETA: 0s - loss: 0.5058 - acc: 0.758 - ETA: 0s - loss: 0.5040 - acc: 0.762 - ETA: 0s - loss: 0.5062 - acc: 0.757 - ETA: 0s - loss: 0.5035 - acc: 0.760 - ETA: 0s - loss: 0.5092 - acc: 0.758 - ETA: 0s - loss: 0.5096 - acc: 0.761 - ETA: 0s - loss: 0.5146 - acc: 0.750 - ETA: 0s - loss: 0.5096 - acc: 0.758 - ETA: 0s - loss: 0.5158 - acc: 0.751 - ETA: 0s - loss: 0.5268 - acc: 0.744 - 1s 2ms/step - loss: 0.5250 - acc: 0.7459 - val_loss: 0.5240 - val_acc: 0.7338\n",
      "Epoch 29/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3079 - acc: 0.900 - ETA: 1s - loss: 0.4451 - acc: 0.750 - ETA: 1s - loss: 0.4648 - acc: 0.757 - ETA: 1s - loss: 0.4842 - acc: 0.750 - ETA: 0s - loss: 0.4984 - acc: 0.746 - ETA: 0s - loss: 0.5034 - acc: 0.743 - ETA: 0s - loss: 0.5202 - acc: 0.736 - ETA: 0s - loss: 0.5090 - acc: 0.745 - ETA: 0s - loss: 0.5147 - acc: 0.740 - ETA: 0s - loss: 0.5197 - acc: 0.728 - ETA: 0s - loss: 0.5171 - acc: 0.732 - ETA: 0s - loss: 0.5075 - acc: 0.738 - ETA: 0s - loss: 0.4971 - acc: 0.751 - ETA: 0s - loss: 0.4968 - acc: 0.752 - ETA: 0s - loss: 0.5077 - acc: 0.741 - ETA: 0s - loss: 0.5041 - acc: 0.745 - ETA: 0s - loss: 0.5056 - acc: 0.746 - ETA: 0s - loss: 0.5059 - acc: 0.753 - ETA: 0s - loss: 0.5080 - acc: 0.754 - ETA: 0s - loss: 0.5128 - acc: 0.748 - ETA: 0s - loss: 0.5199 - acc: 0.741 - 1s 2ms/step - loss: 0.5211 - acc: 0.7394 - val_loss: 0.5192 - val_acc: 0.7403\n",
      "Epoch 30/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.9253 - acc: 0.600 - ETA: 1s - loss: 0.5662 - acc: 0.700 - ETA: 1s - loss: 0.5590 - acc: 0.714 - ETA: 0s - loss: 0.5759 - acc: 0.700 - ETA: 0s - loss: 0.5540 - acc: 0.715 - ETA: 0s - loss: 0.5387 - acc: 0.752 - ETA: 0s - loss: 0.5269 - acc: 0.760 - ETA: 0s - loss: 0.5221 - acc: 0.773 - ETA: 0s - loss: 0.5282 - acc: 0.761 - ETA: 0s - loss: 0.5198 - acc: 0.765 - ETA: 0s - loss: 0.5153 - acc: 0.765 - ETA: 0s - loss: 0.5093 - acc: 0.768 - ETA: 0s - loss: 0.5266 - acc: 0.757 - ETA: 0s - loss: 0.5203 - acc: 0.761 - ETA: 0s - loss: 0.5322 - acc: 0.750 - ETA: 0s - loss: 0.5274 - acc: 0.751 - ETA: 0s - loss: 0.5272 - acc: 0.746 - ETA: 0s - loss: 0.5244 - acc: 0.743 - ETA: 0s - loss: 0.5219 - acc: 0.748 - ETA: 0s - loss: 0.5212 - acc: 0.750 - 1s 2ms/step - loss: 0.5206 - acc: 0.7508 - val_loss: 0.5147 - val_acc: 0.7727\n",
      "Epoch 31/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5415 - acc: 0.600 - ETA: 1s - loss: 0.5215 - acc: 0.775 - ETA: 1s - loss: 0.5355 - acc: 0.714 - ETA: 1s - loss: 0.5162 - acc: 0.760 - ETA: 0s - loss: 0.4926 - acc: 0.792 - ETA: 0s - loss: 0.4754 - acc: 0.800 - ETA: 0s - loss: 0.4685 - acc: 0.805 - ETA: 0s - loss: 0.4778 - acc: 0.790 - ETA: 0s - loss: 0.4918 - acc: 0.784 - ETA: 0s - loss: 0.4847 - acc: 0.785 - ETA: 0s - loss: 0.4971 - acc: 0.777 - ETA: 0s - loss: 0.4921 - acc: 0.770 - ETA: 0s - loss: 0.4855 - acc: 0.773 - ETA: 0s - loss: 0.5030 - acc: 0.762 - ETA: 0s - loss: 0.5013 - acc: 0.762 - ETA: 0s - loss: 0.5042 - acc: 0.756 - ETA: 0s - loss: 0.5044 - acc: 0.758 - ETA: 0s - loss: 0.5108 - acc: 0.751 - ETA: 0s - loss: 0.5110 - acc: 0.749 - ETA: 0s - loss: 0.5134 - acc: 0.744 - ETA: 0s - loss: 0.5147 - acc: 0.742 - 1s 2ms/step - loss: 0.5139 - acc: 0.7459 - val_loss: 0.5107 - val_acc: 0.7597\n",
      "Epoch 32/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.3640 - acc: 0.900 - ETA: 1s - loss: 0.4286 - acc: 0.825 - ETA: 1s - loss: 0.4717 - acc: 0.785 - ETA: 0s - loss: 0.5006 - acc: 0.760 - ETA: 0s - loss: 0.5155 - acc: 0.730 - ETA: 0s - loss: 0.5252 - acc: 0.731 - ETA: 0s - loss: 0.5115 - acc: 0.742 - ETA: 0s - loss: 0.5216 - acc: 0.736 - ETA: 0s - loss: 0.5082 - acc: 0.752 - ETA: 0s - loss: 0.5188 - acc: 0.753 - ETA: 0s - loss: 0.5165 - acc: 0.763 - ETA: 0s - loss: 0.5142 - acc: 0.759 - ETA: 0s - loss: 0.5132 - acc: 0.762 - ETA: 0s - loss: 0.5146 - acc: 0.763 - ETA: 0s - loss: 0.5129 - acc: 0.761 - ETA: 0s - loss: 0.5200 - acc: 0.756 - ETA: 0s - loss: 0.5202 - acc: 0.757 - ETA: 0s - loss: 0.5233 - acc: 0.754 - ETA: 0s - loss: 0.5180 - acc: 0.760 - ETA: 0s - loss: 0.5202 - acc: 0.757 - ETA: 0s - loss: 0.5113 - acc: 0.767 - 1s 2ms/step - loss: 0.5094 - acc: 0.7687 - val_loss: 0.5094 - val_acc: 0.7532\n",
      "Epoch 33/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6382 - acc: 0.600 - ETA: 1s - loss: 0.4844 - acc: 0.800 - ETA: 1s - loss: 0.5345 - acc: 0.728 - ETA: 1s - loss: 0.5088 - acc: 0.770 - ETA: 0s - loss: 0.4894 - acc: 0.800 - ETA: 0s - loss: 0.4838 - acc: 0.800 - ETA: 0s - loss: 0.4832 - acc: 0.800 - ETA: 0s - loss: 0.4794 - acc: 0.800 - ETA: 0s - loss: 0.4980 - acc: 0.773 - ETA: 0s - loss: 0.4935 - acc: 0.766 - ETA: 0s - loss: 0.4877 - acc: 0.773 - ETA: 0s - loss: 0.4890 - acc: 0.782 - ETA: 0s - loss: 0.4985 - acc: 0.773 - ETA: 0s - loss: 0.5015 - acc: 0.773 - ETA: 0s - loss: 0.5171 - acc: 0.759 - ETA: 0s - loss: 0.5164 - acc: 0.755 - ETA: 0s - loss: 0.5081 - acc: 0.760 - ETA: 0s - loss: 0.5084 - acc: 0.758 - ETA: 0s - loss: 0.5047 - acc: 0.760 - ETA: 0s - loss: 0.5082 - acc: 0.759 - 1s 2ms/step - loss: 0.5076 - acc: 0.7590 - val_loss: 0.5025 - val_acc: 0.7792\n",
      "Epoch 34/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5948 - acc: 0.600 - ETA: 1s - loss: 0.4628 - acc: 0.800 - ETA: 0s - loss: 0.4773 - acc: 0.785 - ETA: 0s - loss: 0.5056 - acc: 0.740 - ETA: 0s - loss: 0.5060 - acc: 0.730 - ETA: 0s - loss: 0.4858 - acc: 0.743 - ETA: 0s - loss: 0.4829 - acc: 0.760 - ETA: 0s - loss: 0.4777 - acc: 0.756 - ETA: 0s - loss: 0.4790 - acc: 0.765 - ETA: 0s - loss: 0.4791 - acc: 0.766 - ETA: 0s - loss: 0.4683 - acc: 0.776 - ETA: 0s - loss: 0.4789 - acc: 0.769 - ETA: 0s - loss: 0.4812 - acc: 0.771 - ETA: 0s - loss: 0.4880 - acc: 0.769 - ETA: 0s - loss: 0.4864 - acc: 0.771 - ETA: 0s - loss: 0.4940 - acc: 0.766 - ETA: 0s - loss: 0.4952 - acc: 0.764 - ETA: 0s - loss: 0.4907 - acc: 0.766 - ETA: 0s - loss: 0.4897 - acc: 0.769 - ETA: 0s - loss: 0.4962 - acc: 0.766 - 1s 2ms/step - loss: 0.5007 - acc: 0.7638 - val_loss: 0.5054 - val_acc: 0.7468\n",
      "Epoch 35/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4271 - acc: 0.900 - ETA: 1s - loss: 0.5139 - acc: 0.725 - ETA: 1s - loss: 0.4844 - acc: 0.766 - ETA: 1s - loss: 0.4544 - acc: 0.811 - ETA: 0s - loss: 0.4686 - acc: 0.791 - ETA: 0s - loss: 0.4939 - acc: 0.760 - ETA: 0s - loss: 0.4952 - acc: 0.766 - ETA: 0s - loss: 0.4976 - acc: 0.761 - ETA: 0s - loss: 0.5097 - acc: 0.758 - ETA: 0s - loss: 0.5102 - acc: 0.750 - ETA: 0s - loss: 0.4976 - acc: 0.758 - ETA: 0s - loss: 0.5111 - acc: 0.752 - ETA: 0s - loss: 0.4947 - acc: 0.767 - ETA: 0s - loss: 0.4955 - acc: 0.767 - ETA: 0s - loss: 0.5014 - acc: 0.760 - ETA: 0s - loss: 0.5087 - acc: 0.758 - ETA: 0s - loss: 0.4987 - acc: 0.768 - ETA: 0s - loss: 0.4986 - acc: 0.769 - ETA: 0s - loss: 0.4978 - acc: 0.768 - ETA: 0s - loss: 0.4974 - acc: 0.766 - 1s 2ms/step - loss: 0.4982 - acc: 0.7655 - val_loss: 0.4992 - val_acc: 0.7727\n",
      "Epoch 36/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4610 - acc: 0.800 - ETA: 0s - loss: 0.5533 - acc: 0.700 - ETA: 0s - loss: 0.5085 - acc: 0.744 - ETA: 0s - loss: 0.5137 - acc: 0.753 - ETA: 0s - loss: 0.5086 - acc: 0.750 - ETA: 0s - loss: 0.4995 - acc: 0.760 - ETA: 0s - loss: 0.4945 - acc: 0.765 - ETA: 0s - loss: 0.4987 - acc: 0.759 - ETA: 0s - loss: 0.5071 - acc: 0.763 - ETA: 0s - loss: 0.4991 - acc: 0.772 - ETA: 0s - loss: 0.4971 - acc: 0.778 - ETA: 0s - loss: 0.5006 - acc: 0.772 - ETA: 0s - loss: 0.4959 - acc: 0.776 - ETA: 0s - loss: 0.4879 - acc: 0.778 - ETA: 0s - loss: 0.4905 - acc: 0.774 - ETA: 0s - loss: 0.4897 - acc: 0.776 - ETA: 0s - loss: 0.4971 - acc: 0.767 - 1s 2ms/step - loss: 0.4940 - acc: 0.7704 - val_loss: 0.5038 - val_acc: 0.7597\n",
      "Epoch 37/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.3664 - acc: 0.900 - ETA: 1s - loss: 0.4633 - acc: 0.800 - ETA: 0s - loss: 0.4682 - acc: 0.814 - ETA: 0s - loss: 0.5009 - acc: 0.780 - ETA: 0s - loss: 0.4970 - acc: 0.776 - ETA: 0s - loss: 0.4885 - acc: 0.775 - ETA: 0s - loss: 0.4965 - acc: 0.773 - ETA: 0s - loss: 0.5087 - acc: 0.763 - ETA: 0s - loss: 0.4984 - acc: 0.765 - ETA: 0s - loss: 0.4951 - acc: 0.770 - ETA: 0s - loss: 0.4962 - acc: 0.769 - ETA: 0s - loss: 0.4851 - acc: 0.780 - ETA: 0s - loss: 0.4803 - acc: 0.787 - ETA: 0s - loss: 0.4791 - acc: 0.790 - ETA: 0s - loss: 0.4885 - acc: 0.779 - ETA: 0s - loss: 0.4864 - acc: 0.780 - ETA: 0s - loss: 0.4852 - acc: 0.782 - ETA: 0s - loss: 0.4887 - acc: 0.775 - 1s 2ms/step - loss: 0.4923 - acc: 0.7704 - val_loss: 0.4967 - val_acc: 0.7532\n",
      "Epoch 38/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.7196 - acc: 0.500 - ETA: 1s - loss: 0.6150 - acc: 0.650 - ETA: 1s - loss: 0.5744 - acc: 0.700 - ETA: 0s - loss: 0.5517 - acc: 0.727 - ETA: 0s - loss: 0.5549 - acc: 0.726 - ETA: 0s - loss: 0.5539 - acc: 0.722 - ETA: 0s - loss: 0.5433 - acc: 0.733 - ETA: 0s - loss: 0.5318 - acc: 0.741 - ETA: 0s - loss: 0.5262 - acc: 0.748 - ETA: 0s - loss: 0.5297 - acc: 0.743 - ETA: 0s - loss: 0.5184 - acc: 0.752 - ETA: 0s - loss: 0.5181 - acc: 0.751 - ETA: 0s - loss: 0.5071 - acc: 0.760 - ETA: 0s - loss: 0.5025 - acc: 0.760 - ETA: 0s - loss: 0.5013 - acc: 0.768 - ETA: 0s - loss: 0.4989 - acc: 0.772 - ETA: 0s - loss: 0.4926 - acc: 0.777 - ETA: 0s - loss: 0.4889 - acc: 0.782 - ETA: 0s - loss: 0.4837 - acc: 0.786 - 1s 2ms/step - loss: 0.4883 - acc: 0.7801 - val_loss: 0.5050 - val_acc: 0.7403\n",
      "Epoch 39/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4527 - acc: 0.600 - ETA: 0s - loss: 0.5103 - acc: 0.700 - ETA: 0s - loss: 0.4907 - acc: 0.744 - ETA: 0s - loss: 0.4810 - acc: 0.750 - ETA: 0s - loss: 0.4960 - acc: 0.746 - ETA: 0s - loss: 0.4828 - acc: 0.757 - ETA: 0s - loss: 0.5006 - acc: 0.736 - ETA: 0s - loss: 0.5010 - acc: 0.736 - ETA: 0s - loss: 0.4973 - acc: 0.751 - ETA: 0s - loss: 0.4918 - acc: 0.762 - ETA: 0s - loss: 0.4836 - acc: 0.771 - ETA: 0s - loss: 0.4826 - acc: 0.779 - ETA: 0s - loss: 0.4823 - acc: 0.783 - ETA: 0s - loss: 0.4828 - acc: 0.785 - ETA: 0s - loss: 0.4776 - acc: 0.786 - ETA: 0s - loss: 0.4790 - acc: 0.788 - ETA: 0s - loss: 0.4823 - acc: 0.783 - ETA: 0s - loss: 0.4860 - acc: 0.783 - 1s 2ms/step - loss: 0.4868 - acc: 0.7801 - val_loss: 0.4939 - val_acc: 0.7597\n",
      "Epoch 40/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.3406 - acc: 0.900 - ETA: 1s - loss: 0.3719 - acc: 0.825 - ETA: 1s - loss: 0.4546 - acc: 0.757 - ETA: 1s - loss: 0.4765 - acc: 0.770 - ETA: 1s - loss: 0.5222 - acc: 0.753 - ETA: 0s - loss: 0.5129 - acc: 0.750 - ETA: 0s - loss: 0.5181 - acc: 0.752 - ETA: 0s - loss: 0.5143 - acc: 0.759 - ETA: 0s - loss: 0.5111 - acc: 0.760 - ETA: 0s - loss: 0.4940 - acc: 0.767 - ETA: 0s - loss: 0.4996 - acc: 0.758 - ETA: 0s - loss: 0.4944 - acc: 0.758 - ETA: 0s - loss: 0.4961 - acc: 0.757 - ETA: 0s - loss: 0.5082 - acc: 0.751 - ETA: 0s - loss: 0.5033 - acc: 0.759 - ETA: 0s - loss: 0.4994 - acc: 0.762 - ETA: 0s - loss: 0.4993 - acc: 0.768 - ETA: 0s - loss: 0.4948 - acc: 0.770 - ETA: 0s - loss: 0.4924 - acc: 0.771 - ETA: 0s - loss: 0.4877 - acc: 0.776 - 1s 2ms/step - loss: 0.4839 - acc: 0.7801 - val_loss: 0.4919 - val_acc: 0.7662\n",
      "Epoch 41/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4057 - acc: 0.800 - ETA: 0s - loss: 0.4552 - acc: 0.775 - ETA: 0s - loss: 0.4630 - acc: 0.800 - ETA: 0s - loss: 0.4457 - acc: 0.809 - ETA: 0s - loss: 0.4669 - acc: 0.792 - ETA: 0s - loss: 0.4699 - acc: 0.770 - ETA: 0s - loss: 0.4774 - acc: 0.771 - ETA: 0s - loss: 0.4837 - acc: 0.770 - ETA: 0s - loss: 0.4801 - acc: 0.774 - ETA: 0s - loss: 0.4955 - acc: 0.763 - ETA: 0s - loss: 0.5017 - acc: 0.766 - ETA: 0s - loss: 0.5023 - acc: 0.764 - ETA: 0s - loss: 0.5007 - acc: 0.768 - ETA: 0s - loss: 0.4948 - acc: 0.772 - ETA: 0s - loss: 0.4862 - acc: 0.776 - ETA: 0s - loss: 0.4833 - acc: 0.776 - ETA: 0s - loss: 0.4831 - acc: 0.777 - ETA: 0s - loss: 0.4861 - acc: 0.773 - ETA: 0s - loss: 0.4856 - acc: 0.774 - 1s 2ms/step - loss: 0.4803 - acc: 0.7769 - val_loss: 0.5024 - val_acc: 0.7403\n",
      "Epoch 42/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5418 - acc: 0.700 - ETA: 0s - loss: 0.4274 - acc: 0.800 - ETA: 0s - loss: 0.4685 - acc: 0.762 - ETA: 0s - loss: 0.4617 - acc: 0.780 - ETA: 0s - loss: 0.4861 - acc: 0.753 - ETA: 0s - loss: 0.4654 - acc: 0.775 - ETA: 0s - loss: 0.4649 - acc: 0.773 - ETA: 0s - loss: 0.4650 - acc: 0.768 - ETA: 0s - loss: 0.4896 - acc: 0.748 - ETA: 0s - loss: 0.4890 - acc: 0.746 - ETA: 0s - loss: 0.4965 - acc: 0.741 - ETA: 0s - loss: 0.4924 - acc: 0.748 - ETA: 0s - loss: 0.4819 - acc: 0.758 - ETA: 0s - loss: 0.4863 - acc: 0.761 - ETA: 0s - loss: 0.4920 - acc: 0.758 - ETA: 0s - loss: 0.4909 - acc: 0.758 - ETA: 0s - loss: 0.4869 - acc: 0.760 - ETA: 0s - loss: 0.4887 - acc: 0.765 - ETA: 0s - loss: 0.4846 - acc: 0.775 - ETA: 0s - loss: 0.4899 - acc: 0.770 - ETA: 0s - loss: 0.4889 - acc: 0.775 - ETA: 0s - loss: 0.4840 - acc: 0.778 - 1s 2ms/step - loss: 0.4825 - acc: 0.7801 - val_loss: 0.4883 - val_acc: 0.7727\n",
      "Epoch 43/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4853 - acc: 0.800 - ETA: 0s - loss: 0.4874 - acc: 0.700 - ETA: 0s - loss: 0.4774 - acc: 0.750 - ETA: 0s - loss: 0.4663 - acc: 0.763 - ETA: 0s - loss: 0.4682 - acc: 0.764 - ETA: 0s - loss: 0.4955 - acc: 0.741 - ETA: 0s - loss: 0.5052 - acc: 0.730 - ETA: 0s - loss: 0.5145 - acc: 0.727 - ETA: 0s - loss: 0.5048 - acc: 0.744 - ETA: 0s - loss: 0.4966 - acc: 0.757 - ETA: 0s - loss: 0.4957 - acc: 0.758 - ETA: 0s - loss: 0.4881 - acc: 0.767 - ETA: 0s - loss: 0.4944 - acc: 0.768 - ETA: 0s - loss: 0.4886 - acc: 0.771 - ETA: 0s - loss: 0.4826 - acc: 0.773 - ETA: 0s - loss: 0.4741 - acc: 0.781 - ETA: 0s - loss: 0.4652 - acc: 0.786 - ETA: 0s - loss: 0.4655 - acc: 0.790 - ETA: 0s - loss: 0.4675 - acc: 0.791 - 1s 2ms/step - loss: 0.4790 - acc: 0.7834 - val_loss: 0.4908 - val_acc: 0.7597\n",
      "Epoch 44/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5020 - acc: 0.700 - ETA: 1s - loss: 0.5735 - acc: 0.775 - ETA: 0s - loss: 0.5070 - acc: 0.762 - ETA: 0s - loss: 0.5302 - acc: 0.736 - ETA: 0s - loss: 0.5059 - acc: 0.757 - ETA: 0s - loss: 0.4736 - acc: 0.788 - ETA: 0s - loss: 0.4871 - acc: 0.776 - ETA: 0s - loss: 0.4788 - acc: 0.787 - ETA: 0s - loss: 0.4690 - acc: 0.796 - ETA: 0s - loss: 0.4726 - acc: 0.796 - ETA: 0s - loss: 0.4676 - acc: 0.800 - ETA: 0s - loss: 0.4746 - acc: 0.789 - ETA: 0s - loss: 0.4735 - acc: 0.790 - ETA: 0s - loss: 0.4753 - acc: 0.786 - ETA: 0s - loss: 0.4666 - acc: 0.791 - ETA: 0s - loss: 0.4741 - acc: 0.782 - ETA: 0s - loss: 0.4722 - acc: 0.783 - ETA: 0s - loss: 0.4696 - acc: 0.784 - 1s 2ms/step - loss: 0.4750 - acc: 0.7818 - val_loss: 0.4844 - val_acc: 0.7792\n",
      "Epoch 45/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - ETA: 1s - loss: 0.4581 - acc: 0.800 - ETA: 1s - loss: 0.4584 - acc: 0.800 - ETA: 1s - loss: 0.4388 - acc: 0.785 - ETA: 0s - loss: 0.4650 - acc: 0.780 - ETA: 0s - loss: 0.4711 - acc: 0.769 - ETA: 0s - loss: 0.4836 - acc: 0.762 - ETA: 0s - loss: 0.4886 - acc: 0.768 - ETA: 0s - loss: 0.4902 - acc: 0.759 - ETA: 0s - loss: 0.4966 - acc: 0.757 - ETA: 0s - loss: 0.5044 - acc: 0.750 - ETA: 0s - loss: 0.4986 - acc: 0.754 - ETA: 0s - loss: 0.4884 - acc: 0.761 - ETA: 0s - loss: 0.4914 - acc: 0.759 - ETA: 0s - loss: 0.4865 - acc: 0.769 - ETA: 0s - loss: 0.4853 - acc: 0.768 - ETA: 0s - loss: 0.4812 - acc: 0.770 - ETA: 0s - loss: 0.4835 - acc: 0.768 - ETA: 0s - loss: 0.4813 - acc: 0.774 - ETA: 0s - loss: 0.4787 - acc: 0.774 - ETA: 0s - loss: 0.4762 - acc: 0.775 - 1s 2ms/step - loss: 0.4738 - acc: 0.7785 - val_loss: 0.4831 - val_acc: 0.7727\n",
      "Epoch 46/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5285 - acc: 0.700 - ETA: 1s - loss: 0.4956 - acc: 0.775 - ETA: 0s - loss: 0.5054 - acc: 0.771 - ETA: 0s - loss: 0.5173 - acc: 0.760 - ETA: 0s - loss: 0.5503 - acc: 0.738 - ETA: 0s - loss: 0.5202 - acc: 0.764 - ETA: 0s - loss: 0.5000 - acc: 0.790 - ETA: 0s - loss: 0.4809 - acc: 0.796 - ETA: 0s - loss: 0.4674 - acc: 0.810 - ETA: 0s - loss: 0.4644 - acc: 0.815 - ETA: 0s - loss: 0.4663 - acc: 0.805 - ETA: 0s - loss: 0.4681 - acc: 0.797 - ETA: 0s - loss: 0.4682 - acc: 0.792 - ETA: 0s - loss: 0.4634 - acc: 0.793 - ETA: 0s - loss: 0.4576 - acc: 0.795 - ETA: 0s - loss: 0.4555 - acc: 0.796 - ETA: 0s - loss: 0.4564 - acc: 0.794 - ETA: 0s - loss: 0.4619 - acc: 0.791 - ETA: 0s - loss: 0.4707 - acc: 0.786 - 1s 2ms/step - loss: 0.4707 - acc: 0.7866 - val_loss: 0.4815 - val_acc: 0.7727\n",
      "Epoch 47/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5273 - acc: 0.700 - ETA: 0s - loss: 0.5394 - acc: 0.750 - ETA: 0s - loss: 0.5011 - acc: 0.757 - ETA: 0s - loss: 0.4499 - acc: 0.809 - ETA: 0s - loss: 0.4618 - acc: 0.792 - ETA: 0s - loss: 0.4323 - acc: 0.811 - ETA: 0s - loss: 0.4186 - acc: 0.819 - ETA: 0s - loss: 0.4401 - acc: 0.804 - ETA: 0s - loss: 0.4701 - acc: 0.782 - ETA: 0s - loss: 0.4662 - acc: 0.784 - ETA: 0s - loss: 0.4593 - acc: 0.788 - ETA: 0s - loss: 0.4538 - acc: 0.792 - ETA: 0s - loss: 0.4726 - acc: 0.784 - ETA: 0s - loss: 0.4679 - acc: 0.783 - ETA: 0s - loss: 0.4722 - acc: 0.780 - ETA: 0s - loss: 0.4677 - acc: 0.783 - ETA: 0s - loss: 0.4671 - acc: 0.783 - 1s 2ms/step - loss: 0.4696 - acc: 0.7785 - val_loss: 0.4874 - val_acc: 0.7727\n",
      "Epoch 48/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.7244 - acc: 0.700 - ETA: 0s - loss: 0.3802 - acc: 0.875 - ETA: 0s - loss: 0.4576 - acc: 0.800 - ETA: 0s - loss: 0.4550 - acc: 0.800 - ETA: 0s - loss: 0.4612 - acc: 0.778 - ETA: 0s - loss: 0.4724 - acc: 0.766 - ETA: 0s - loss: 0.4735 - acc: 0.771 - ETA: 0s - loss: 0.4786 - acc: 0.772 - ETA: 0s - loss: 0.4738 - acc: 0.775 - ETA: 0s - loss: 0.4736 - acc: 0.772 - ETA: 0s - loss: 0.4644 - acc: 0.778 - ETA: 0s - loss: 0.4650 - acc: 0.780 - ETA: 0s - loss: 0.4574 - acc: 0.790 - ETA: 0s - loss: 0.4626 - acc: 0.787 - ETA: 0s - loss: 0.4702 - acc: 0.780 - ETA: 0s - loss: 0.4647 - acc: 0.783 - ETA: 0s - loss: 0.4645 - acc: 0.783 - ETA: 0s - loss: 0.4665 - acc: 0.781 - 1s 2ms/step - loss: 0.4682 - acc: 0.7801 - val_loss: 0.4760 - val_acc: 0.7662\n",
      "Epoch 49/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.2159 - acc: 1.000 - ETA: 0s - loss: 0.3387 - acc: 0.880 - ETA: 0s - loss: 0.3486 - acc: 0.862 - ETA: 0s - loss: 0.3922 - acc: 0.833 - ETA: 0s - loss: 0.4246 - acc: 0.800 - ETA: 0s - loss: 0.4420 - acc: 0.784 - ETA: 0s - loss: 0.4597 - acc: 0.778 - ETA: 0s - loss: 0.4693 - acc: 0.776 - ETA: 0s - loss: 0.4818 - acc: 0.762 - ETA: 0s - loss: 0.4686 - acc: 0.769 - ETA: 0s - loss: 0.4652 - acc: 0.775 - ETA: 0s - loss: 0.4660 - acc: 0.775 - ETA: 0s - loss: 0.4597 - acc: 0.776 - ETA: 0s - loss: 0.4660 - acc: 0.776 - ETA: 0s - loss: 0.4697 - acc: 0.774 - ETA: 0s - loss: 0.4749 - acc: 0.771 - ETA: 0s - loss: 0.4683 - acc: 0.776 - ETA: 0s - loss: 0.4705 - acc: 0.775 - 1s 2ms/step - loss: 0.4650 - acc: 0.7801 - val_loss: 0.4841 - val_acc: 0.7792\n",
      "Epoch 50/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6136 - acc: 0.700 - ETA: 1s - loss: 0.4713 - acc: 0.800 - ETA: 1s - loss: 0.5071 - acc: 0.800 - ETA: 1s - loss: 0.4972 - acc: 0.770 - ETA: 0s - loss: 0.4791 - acc: 0.776 - ETA: 0s - loss: 0.4751 - acc: 0.787 - ETA: 0s - loss: 0.4546 - acc: 0.810 - ETA: 0s - loss: 0.4646 - acc: 0.786 - ETA: 0s - loss: 0.4701 - acc: 0.776 - ETA: 0s - loss: 0.4587 - acc: 0.782 - ETA: 0s - loss: 0.4547 - acc: 0.787 - ETA: 0s - loss: 0.4592 - acc: 0.788 - ETA: 0s - loss: 0.4597 - acc: 0.786 - ETA: 0s - loss: 0.4613 - acc: 0.785 - ETA: 0s - loss: 0.4722 - acc: 0.781 - ETA: 0s - loss: 0.4722 - acc: 0.780 - ETA: 0s - loss: 0.4734 - acc: 0.779 - ETA: 0s - loss: 0.4758 - acc: 0.776 - ETA: 0s - loss: 0.4732 - acc: 0.780 - ETA: 0s - loss: 0.4696 - acc: 0.784 - ETA: 0s - loss: 0.4684 - acc: 0.786 - 1s 2ms/step - loss: 0.4663 - acc: 0.7883 - val_loss: 0.4757 - val_acc: 0.7727\n",
      "Epoch 51/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.2875 - acc: 0.900 - ETA: 1s - loss: 0.4087 - acc: 0.850 - ETA: 1s - loss: 0.4656 - acc: 0.785 - ETA: 1s - loss: 0.4416 - acc: 0.800 - ETA: 1s - loss: 0.4517 - acc: 0.816 - ETA: 0s - loss: 0.4609 - acc: 0.813 - ETA: 0s - loss: 0.4825 - acc: 0.777 - ETA: 0s - loss: 0.4822 - acc: 0.781 - ETA: 0s - loss: 0.4856 - acc: 0.775 - ETA: 0s - loss: 0.4794 - acc: 0.781 - ETA: 0s - loss: 0.4841 - acc: 0.776 - ETA: 0s - loss: 0.4822 - acc: 0.769 - ETA: 0s - loss: 0.4775 - acc: 0.769 - ETA: 0s - loss: 0.4759 - acc: 0.774 - ETA: 0s - loss: 0.4732 - acc: 0.776 - ETA: 0s - loss: 0.4701 - acc: 0.782 - ETA: 0s - loss: 0.4647 - acc: 0.787 - ETA: 0s - loss: 0.4714 - acc: 0.788 - ETA: 0s - loss: 0.4688 - acc: 0.790 - ETA: 0s - loss: 0.4713 - acc: 0.787 - ETA: 0s - loss: 0.4652 - acc: 0.793 - 1s 2ms/step - loss: 0.4637 - acc: 0.7932 - val_loss: 0.4742 - val_acc: 0.7727\n",
      "Epoch 52/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.3889 - acc: 0.800 - ETA: 0s - loss: 0.3841 - acc: 0.840 - ETA: 0s - loss: 0.3889 - acc: 0.850 - ETA: 0s - loss: 0.4170 - acc: 0.818 - ETA: 0s - loss: 0.4461 - acc: 0.800 - ETA: 0s - loss: 0.4561 - acc: 0.800 - ETA: 0s - loss: 0.4606 - acc: 0.795 - ETA: 0s - loss: 0.4617 - acc: 0.795 - ETA: 0s - loss: 0.4660 - acc: 0.792 - ETA: 0s - loss: 0.4611 - acc: 0.789 - ETA: 0s - loss: 0.4573 - acc: 0.793 - ETA: 0s - loss: 0.4631 - acc: 0.788 - ETA: 0s - loss: 0.4580 - acc: 0.797 - ETA: 0s - loss: 0.4596 - acc: 0.795 - ETA: 0s - loss: 0.4605 - acc: 0.795 - ETA: 0s - loss: 0.4656 - acc: 0.785 - ETA: 0s - loss: 0.4655 - acc: 0.784 - ETA: 0s - loss: 0.4683 - acc: 0.779 - ETA: 0s - loss: 0.4632 - acc: 0.785 - ETA: 0s - loss: 0.4606 - acc: 0.788 - 1s 2ms/step - loss: 0.4629 - acc: 0.7899 - val_loss: 0.4739 - val_acc: 0.7662\n",
      "Epoch 53/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.3326 - acc: 0.900 - ETA: 1s - loss: 0.4642 - acc: 0.775 - ETA: 0s - loss: 0.4831 - acc: 0.757 - ETA: 0s - loss: 0.4483 - acc: 0.780 - ETA: 0s - loss: 0.4313 - acc: 0.800 - ETA: 0s - loss: 0.4485 - acc: 0.775 - ETA: 0s - loss: 0.4372 - acc: 0.794 - ETA: 0s - loss: 0.4281 - acc: 0.800 - ETA: 0s - loss: 0.4158 - acc: 0.820 - ETA: 0s - loss: 0.4227 - acc: 0.814 - ETA: 0s - loss: 0.4166 - acc: 0.816 - ETA: 0s - loss: 0.4185 - acc: 0.808 - ETA: 0s - loss: 0.4279 - acc: 0.797 - ETA: 0s - loss: 0.4330 - acc: 0.797 - ETA: 0s - loss: 0.4480 - acc: 0.788 - ETA: 0s - loss: 0.4521 - acc: 0.793 - ETA: 0s - loss: 0.4553 - acc: 0.793 - ETA: 0s - loss: 0.4534 - acc: 0.796 - ETA: 0s - loss: 0.4614 - acc: 0.787 - ETA: 0s - loss: 0.4619 - acc: 0.786 - 1s 2ms/step - loss: 0.4601 - acc: 0.7883 - val_loss: 0.4828 - val_acc: 0.7662\n",
      "Epoch 54/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 1.0052 - acc: 0.400 - ETA: 0s - loss: 0.5503 - acc: 0.660 - ETA: 0s - loss: 0.4981 - acc: 0.712 - ETA: 0s - loss: 0.4977 - acc: 0.718 - ETA: 0s - loss: 0.4827 - acc: 0.728 - ETA: 0s - loss: 0.4987 - acc: 0.729 - ETA: 0s - loss: 0.4869 - acc: 0.745 - ETA: 0s - loss: 0.4954 - acc: 0.734 - ETA: 0s - loss: 0.4891 - acc: 0.736 - ETA: 0s - loss: 0.4835 - acc: 0.746 - ETA: 0s - loss: 0.4758 - acc: 0.754 - ETA: 0s - loss: 0.4649 - acc: 0.761 - ETA: 0s - loss: 0.4599 - acc: 0.770 - ETA: 0s - loss: 0.4593 - acc: 0.770 - ETA: 0s - loss: 0.4709 - acc: 0.762 - ETA: 0s - loss: 0.4704 - acc: 0.766 - ETA: 0s - loss: 0.4584 - acc: 0.778 - ETA: 0s - loss: 0.4697 - acc: 0.774 - ETA: 0s - loss: 0.4604 - acc: 0.778 - ETA: 0s - loss: 0.4660 - acc: 0.773 - 1s 2ms/step - loss: 0.4645 - acc: 0.7752 - val_loss: 0.4802 - val_acc: 0.7597\n",
      "Epoch 55/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5005 - acc: 0.800 - ETA: 1s - loss: 0.4258 - acc: 0.825 - ETA: 1s - loss: 0.4084 - acc: 0.828 - ETA: 1s - loss: 0.4188 - acc: 0.820 - ETA: 0s - loss: 0.4509 - acc: 0.800 - ETA: 0s - loss: 0.4693 - acc: 0.800 - ETA: 0s - loss: 0.4669 - acc: 0.800 - ETA: 0s - loss: 0.4808 - acc: 0.786 - ETA: 0s - loss: 0.4810 - acc: 0.780 - ETA: 0s - loss: 0.4764 - acc: 0.782 - ETA: 0s - loss: 0.4818 - acc: 0.771 - ETA: 0s - loss: 0.4810 - acc: 0.767 - ETA: 0s - loss: 0.4720 - acc: 0.773 - ETA: 0s - loss: 0.4696 - acc: 0.776 - ETA: 0s - loss: 0.4702 - acc: 0.780 - ETA: 0s - loss: 0.4684 - acc: 0.779 - ETA: 0s - loss: 0.4652 - acc: 0.778 - ETA: 0s - loss: 0.4720 - acc: 0.774 - ETA: 0s - loss: 0.4653 - acc: 0.777 - ETA: 0s - loss: 0.4615 - acc: 0.780 - 1s 2ms/step - loss: 0.4608 - acc: 0.7818 - val_loss: 0.4721 - val_acc: 0.7727\n",
      "Epoch 56/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5193 - acc: 0.700 - ETA: 1s - loss: 0.4692 - acc: 0.750 - ETA: 1s - loss: 0.4608 - acc: 0.771 - ETA: 0s - loss: 0.4395 - acc: 0.770 - ETA: 0s - loss: 0.4368 - acc: 0.785 - ETA: 0s - loss: 0.4167 - acc: 0.800 - ETA: 0s - loss: 0.4298 - acc: 0.795 - ETA: 0s - loss: 0.4532 - acc: 0.788 - ETA: 0s - loss: 0.4600 - acc: 0.785 - ETA: 0s - loss: 0.4657 - acc: 0.774 - ETA: 0s - loss: 0.4649 - acc: 0.782 - ETA: 0s - loss: 0.4729 - acc: 0.775 - ETA: 0s - loss: 0.4689 - acc: 0.780 - ETA: 0s - loss: 0.4641 - acc: 0.781 - ETA: 0s - loss: 0.4575 - acc: 0.783 - ETA: 0s - loss: 0.4592 - acc: 0.778 - ETA: 0s - loss: 0.4626 - acc: 0.777 - ETA: 0s - loss: 0.4603 - acc: 0.781 - ETA: 0s - loss: 0.4578 - acc: 0.784 - 1s 2ms/step - loss: 0.4576 - acc: 0.7818 - val_loss: 0.4690 - val_acc: 0.7987\n",
      "Epoch 57/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4154 - acc: 0.800 - ETA: 1s - loss: 0.4254 - acc: 0.825 - ETA: 1s - loss: 0.4600 - acc: 0.800 - ETA: 0s - loss: 0.4248 - acc: 0.820 - ETA: 0s - loss: 0.4587 - acc: 0.800 - ETA: 0s - loss: 0.4742 - acc: 0.777 - ETA: 0s - loss: 0.4719 - acc: 0.781 - ETA: 0s - loss: 0.4609 - acc: 0.791 - ETA: 0s - loss: 0.4754 - acc: 0.777 - ETA: 0s - loss: 0.4697 - acc: 0.776 - ETA: 0s - loss: 0.4660 - acc: 0.772 - ETA: 0s - loss: 0.4682 - acc: 0.775 - ETA: 0s - loss: 0.4662 - acc: 0.782 - ETA: 0s - loss: 0.4680 - acc: 0.781 - ETA: 0s - loss: 0.4567 - acc: 0.786 - ETA: 0s - loss: 0.4449 - acc: 0.795 - ETA: 0s - loss: 0.4592 - acc: 0.782 - ETA: 0s - loss: 0.4623 - acc: 0.783 - ETA: 0s - loss: 0.4660 - acc: 0.780 - ETA: 0s - loss: 0.4642 - acc: 0.780 - 1s 2ms/step - loss: 0.4597 - acc: 0.7834 - val_loss: 0.4776 - val_acc: 0.7597\n",
      "Epoch 58/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6400 - acc: 0.600 - ETA: 0s - loss: 0.4543 - acc: 0.820 - ETA: 0s - loss: 0.4719 - acc: 0.787 - ETA: 0s - loss: 0.4634 - acc: 0.800 - ETA: 0s - loss: 0.4540 - acc: 0.807 - ETA: 0s - loss: 0.4529 - acc: 0.805 - ETA: 0s - loss: 0.4847 - acc: 0.776 - ETA: 0s - loss: 0.4819 - acc: 0.775 - ETA: 0s - loss: 0.4799 - acc: 0.774 - ETA: 0s - loss: 0.4786 - acc: 0.770 - ETA: 0s - loss: 0.4807 - acc: 0.771 - ETA: 0s - loss: 0.4782 - acc: 0.773 - ETA: 0s - loss: 0.4850 - acc: 0.770 - ETA: 0s - loss: 0.4852 - acc: 0.770 - ETA: 0s - loss: 0.4703 - acc: 0.779 - ETA: 0s - loss: 0.4658 - acc: 0.780 - ETA: 0s - loss: 0.4584 - acc: 0.785 - ETA: 0s - loss: 0.4629 - acc: 0.784 - ETA: 0s - loss: 0.4618 - acc: 0.783 - ETA: 0s - loss: 0.4551 - acc: 0.787 - 1s 2ms/step - loss: 0.4572 - acc: 0.7866 - val_loss: 0.4746 - val_acc: 0.7597\n",
      "Epoch 59/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4762 - acc: 0.800 - ETA: 0s - loss: 0.4742 - acc: 0.760 - ETA: 0s - loss: 0.4940 - acc: 0.775 - ETA: 0s - loss: 0.4800 - acc: 0.790 - ETA: 0s - loss: 0.4811 - acc: 0.785 - ETA: 0s - loss: 0.4704 - acc: 0.782 - ETA: 0s - loss: 0.4704 - acc: 0.790 - ETA: 0s - loss: 0.4625 - acc: 0.800 - ETA: 0s - loss: 0.4641 - acc: 0.796 - ETA: 0s - loss: 0.4719 - acc: 0.793 - ETA: 0s - loss: 0.4707 - acc: 0.790 - ETA: 0s - loss: 0.4677 - acc: 0.788 - ETA: 0s - loss: 0.4656 - acc: 0.786 - ETA: 0s - loss: 0.4638 - acc: 0.787 - ETA: 0s - loss: 0.4720 - acc: 0.781 - ETA: 0s - loss: 0.4632 - acc: 0.789 - ETA: 0s - loss: 0.4568 - acc: 0.796 - ETA: 0s - loss: 0.4512 - acc: 0.798 - ETA: 0s - loss: 0.4552 - acc: 0.796 - ETA: 0s - loss: 0.4516 - acc: 0.796 - 1s 2ms/step - loss: 0.4552 - acc: 0.7932 - val_loss: 0.4708 - val_acc: 0.7792\n",
      "Epoch 60/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5459 - acc: 0.800 - ETA: 0s - loss: 0.4878 - acc: 0.800 - ETA: 0s - loss: 0.5032 - acc: 0.785 - ETA: 0s - loss: 0.4883 - acc: 0.800 - ETA: 0s - loss: 0.4746 - acc: 0.792 - ETA: 0s - loss: 0.4602 - acc: 0.800 - ETA: 0s - loss: 0.4436 - acc: 0.815 - ETA: 0s - loss: 0.4716 - acc: 0.782 - ETA: 0s - loss: 0.4593 - acc: 0.796 - ETA: 0s - loss: 0.4558 - acc: 0.796 - ETA: 0s - loss: 0.4450 - acc: 0.800 - ETA: 0s - loss: 0.4497 - acc: 0.797 - ETA: 0s - loss: 0.4431 - acc: 0.797 - ETA: 0s - loss: 0.4448 - acc: 0.797 - ETA: 0s - loss: 0.4539 - acc: 0.788 - ETA: 0s - loss: 0.4589 - acc: 0.780 - ETA: 0s - loss: 0.4653 - acc: 0.776 - ETA: 0s - loss: 0.4543 - acc: 0.783 - ETA: 0s - loss: 0.4581 - acc: 0.780 - ETA: 0s - loss: 0.4563 - acc: 0.783 - 1s 2ms/step - loss: 0.4550 - acc: 0.7834 - val_loss: 0.4722 - val_acc: 0.7662\n",
      "Epoch 61/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3639 - acc: 0.900 - ETA: 0s - loss: 0.4941 - acc: 0.760 - ETA: 0s - loss: 0.5141 - acc: 0.744 - ETA: 0s - loss: 0.4719 - acc: 0.775 - ETA: 0s - loss: 0.4784 - acc: 0.773 - ETA: 0s - loss: 0.4415 - acc: 0.794 - ETA: 0s - loss: 0.4413 - acc: 0.795 - ETA: 0s - loss: 0.4363 - acc: 0.796 - ETA: 0s - loss: 0.4626 - acc: 0.786 - ETA: 0s - loss: 0.4541 - acc: 0.793 - ETA: 0s - loss: 0.4486 - acc: 0.797 - ETA: 0s - loss: 0.4481 - acc: 0.797 - ETA: 0s - loss: 0.4493 - acc: 0.793 - ETA: 0s - loss: 0.4507 - acc: 0.797 - ETA: 0s - loss: 0.4475 - acc: 0.800 - ETA: 0s - loss: 0.4493 - acc: 0.794 - ETA: 0s - loss: 0.4500 - acc: 0.792 - ETA: 0s - loss: 0.4514 - acc: 0.791 - ETA: 0s - loss: 0.4511 - acc: 0.793 - 1s 2ms/step - loss: 0.4527 - acc: 0.7932 - val_loss: 0.4703 - val_acc: 0.7857\n",
      "Epoch 62/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6498 - acc: 0.800 - ETA: 1s - loss: 0.5705 - acc: 0.725 - ETA: 0s - loss: 0.5100 - acc: 0.757 - ETA: 0s - loss: 0.5085 - acc: 0.750 - ETA: 0s - loss: 0.4817 - acc: 0.776 - ETA: 0s - loss: 0.4735 - acc: 0.781 - ETA: 0s - loss: 0.4695 - acc: 0.789 - ETA: 0s - loss: 0.4700 - acc: 0.790 - ETA: 0s - loss: 0.4617 - acc: 0.792 - ETA: 0s - loss: 0.4560 - acc: 0.796 - ETA: 0s - loss: 0.4635 - acc: 0.783 - ETA: 0s - loss: 0.4581 - acc: 0.785 - ETA: 0s - loss: 0.4516 - acc: 0.786 - ETA: 0s - loss: 0.4536 - acc: 0.787 - ETA: 0s - loss: 0.4489 - acc: 0.790 - ETA: 0s - loss: 0.4566 - acc: 0.789 - ETA: 0s - loss: 0.4541 - acc: 0.790 - ETA: 0s - loss: 0.4546 - acc: 0.792 - ETA: 0s - loss: 0.4592 - acc: 0.785 - ETA: 0s - loss: 0.4555 - acc: 0.788 - 1s 2ms/step - loss: 0.4530 - acc: 0.7899 - val_loss: 0.4710 - val_acc: 0.7792\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - ETA: 1s - loss: 0.5064 - acc: 0.800 - ETA: 0s - loss: 0.4754 - acc: 0.780 - ETA: 0s - loss: 0.4763 - acc: 0.762 - ETA: 0s - loss: 0.4666 - acc: 0.766 - ETA: 0s - loss: 0.4647 - acc: 0.760 - ETA: 0s - loss: 0.4631 - acc: 0.761 - ETA: 0s - loss: 0.4662 - acc: 0.761 - ETA: 0s - loss: 0.4643 - acc: 0.770 - ETA: 0s - loss: 0.4670 - acc: 0.766 - ETA: 0s - loss: 0.4683 - acc: 0.760 - ETA: 0s - loss: 0.4642 - acc: 0.766 - ETA: 0s - loss: 0.4711 - acc: 0.765 - ETA: 0s - loss: 0.4696 - acc: 0.763 - ETA: 0s - loss: 0.4739 - acc: 0.764 - ETA: 0s - loss: 0.4627 - acc: 0.773 - ETA: 0s - loss: 0.4648 - acc: 0.775 - ETA: 0s - loss: 0.4557 - acc: 0.782 - ETA: 0s - loss: 0.4495 - acc: 0.783 - ETA: 0s - loss: 0.4554 - acc: 0.783 - 1s 2ms/step - loss: 0.4542 - acc: 0.7834 - val_loss: 0.4735 - val_acc: 0.7727\n",
      "Epoch 64/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5559 - acc: 0.600 - ETA: 0s - loss: 0.5270 - acc: 0.725 - ETA: 0s - loss: 0.5299 - acc: 0.728 - ETA: 0s - loss: 0.5193 - acc: 0.710 - ETA: 0s - loss: 0.4801 - acc: 0.757 - ETA: 0s - loss: 0.4746 - acc: 0.758 - ETA: 0s - loss: 0.4666 - acc: 0.775 - ETA: 0s - loss: 0.4548 - acc: 0.779 - ETA: 0s - loss: 0.4390 - acc: 0.785 - ETA: 0s - loss: 0.4450 - acc: 0.783 - ETA: 0s - loss: 0.4372 - acc: 0.788 - ETA: 0s - loss: 0.4453 - acc: 0.781 - ETA: 0s - loss: 0.4535 - acc: 0.782 - ETA: 0s - loss: 0.4617 - acc: 0.776 - ETA: 0s - loss: 0.4631 - acc: 0.774 - ETA: 0s - loss: 0.4608 - acc: 0.776 - ETA: 0s - loss: 0.4483 - acc: 0.787 - ETA: 0s - loss: 0.4539 - acc: 0.781 - ETA: 0s - loss: 0.4530 - acc: 0.782 - 1s 2ms/step - loss: 0.4541 - acc: 0.7801 - val_loss: 0.4695 - val_acc: 0.7792\n",
      "Epoch 65/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5641 - acc: 0.800 - ETA: 0s - loss: 0.4668 - acc: 0.820 - ETA: 0s - loss: 0.4968 - acc: 0.750 - ETA: 0s - loss: 0.5496 - acc: 0.716 - ETA: 0s - loss: 0.5371 - acc: 0.726 - ETA: 0s - loss: 0.4982 - acc: 0.752 - ETA: 0s - loss: 0.4950 - acc: 0.763 - ETA: 0s - loss: 0.4818 - acc: 0.768 - ETA: 0s - loss: 0.4758 - acc: 0.767 - ETA: 0s - loss: 0.4822 - acc: 0.767 - ETA: 0s - loss: 0.4623 - acc: 0.782 - ETA: 0s - loss: 0.4777 - acc: 0.770 - ETA: 0s - loss: 0.4604 - acc: 0.785 - ETA: 0s - loss: 0.4657 - acc: 0.780 - ETA: 0s - loss: 0.4670 - acc: 0.771 - ETA: 0s - loss: 0.4673 - acc: 0.771 - ETA: 0s - loss: 0.4561 - acc: 0.780 - ETA: 0s - loss: 0.4544 - acc: 0.785 - 1s 2ms/step - loss: 0.4509 - acc: 0.7866 - val_loss: 0.4688 - val_acc: 0.7922\n",
      "Epoch 66/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4948 - acc: 0.600 - ETA: 1s - loss: 0.4315 - acc: 0.775 - ETA: 0s - loss: 0.4210 - acc: 0.800 - ETA: 0s - loss: 0.4310 - acc: 0.810 - ETA: 0s - loss: 0.4403 - acc: 0.791 - ETA: 0s - loss: 0.4163 - acc: 0.813 - ETA: 0s - loss: 0.4257 - acc: 0.816 - ETA: 0s - loss: 0.4276 - acc: 0.809 - ETA: 0s - loss: 0.4293 - acc: 0.812 - ETA: 0s - loss: 0.4369 - acc: 0.803 - ETA: 0s - loss: 0.4335 - acc: 0.806 - ETA: 0s - loss: 0.4339 - acc: 0.805 - ETA: 0s - loss: 0.4461 - acc: 0.794 - ETA: 0s - loss: 0.4437 - acc: 0.795 - ETA: 0s - loss: 0.4449 - acc: 0.790 - ETA: 0s - loss: 0.4438 - acc: 0.793 - ETA: 0s - loss: 0.4416 - acc: 0.798 - ETA: 0s - loss: 0.4483 - acc: 0.796 - ETA: 0s - loss: 0.4522 - acc: 0.791 - 1s 2ms/step - loss: 0.4496 - acc: 0.7915 - val_loss: 0.4760 - val_acc: 0.7597\n",
      "Epoch 67/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.6527 - acc: 0.800 - ETA: 1s - loss: 0.4884 - acc: 0.800 - ETA: 1s - loss: 0.5255 - acc: 0.760 - ETA: 1s - loss: 0.5054 - acc: 0.762 - ETA: 1s - loss: 0.4555 - acc: 0.809 - ETA: 1s - loss: 0.4372 - acc: 0.807 - ETA: 0s - loss: 0.4581 - acc: 0.800 - ETA: 0s - loss: 0.4560 - acc: 0.790 - ETA: 0s - loss: 0.4510 - acc: 0.791 - ETA: 0s - loss: 0.4592 - acc: 0.788 - ETA: 0s - loss: 0.4549 - acc: 0.789 - ETA: 0s - loss: 0.4399 - acc: 0.803 - ETA: 0s - loss: 0.4391 - acc: 0.805 - ETA: 0s - loss: 0.4398 - acc: 0.802 - ETA: 0s - loss: 0.4366 - acc: 0.807 - ETA: 0s - loss: 0.4377 - acc: 0.802 - ETA: 0s - loss: 0.4355 - acc: 0.802 - ETA: 0s - loss: 0.4367 - acc: 0.798 - ETA: 0s - loss: 0.4376 - acc: 0.794 - ETA: 0s - loss: 0.4435 - acc: 0.785 - ETA: 0s - loss: 0.4539 - acc: 0.781 - ETA: 0s - loss: 0.4495 - acc: 0.786 - 1s 2ms/step - loss: 0.4477 - acc: 0.7883 - val_loss: 0.4675 - val_acc: 0.7727\n",
      "Epoch 68/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4548 - acc: 0.800 - ETA: 0s - loss: 0.4226 - acc: 0.760 - ETA: 0s - loss: 0.4478 - acc: 0.750 - ETA: 0s - loss: 0.4749 - acc: 0.754 - ETA: 0s - loss: 0.4706 - acc: 0.753 - ETA: 0s - loss: 0.4699 - acc: 0.755 - ETA: 0s - loss: 0.4441 - acc: 0.781 - ETA: 0s - loss: 0.4409 - acc: 0.783 - ETA: 0s - loss: 0.4293 - acc: 0.792 - ETA: 0s - loss: 0.4435 - acc: 0.780 - ETA: 0s - loss: 0.4492 - acc: 0.779 - ETA: 0s - loss: 0.4458 - acc: 0.781 - ETA: 0s - loss: 0.4503 - acc: 0.778 - ETA: 0s - loss: 0.4485 - acc: 0.779 - ETA: 0s - loss: 0.4510 - acc: 0.779 - ETA: 0s - loss: 0.4600 - acc: 0.778 - ETA: 0s - loss: 0.4578 - acc: 0.781 - ETA: 0s - loss: 0.4515 - acc: 0.786 - ETA: 0s - loss: 0.4498 - acc: 0.786 - 1s 2ms/step - loss: 0.4495 - acc: 0.7883 - val_loss: 0.4701 - val_acc: 0.7792\n",
      "Epoch 69/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.7389 - acc: 0.600 - ETA: 0s - loss: 0.4773 - acc: 0.760 - ETA: 0s - loss: 0.4233 - acc: 0.811 - ETA: 0s - loss: 0.4168 - acc: 0.830 - ETA: 0s - loss: 0.4300 - acc: 0.825 - ETA: 0s - loss: 0.4403 - acc: 0.820 - ETA: 0s - loss: 0.4431 - acc: 0.808 - ETA: 0s - loss: 0.4486 - acc: 0.800 - ETA: 0s - loss: 0.4451 - acc: 0.803 - ETA: 0s - loss: 0.4341 - acc: 0.806 - ETA: 0s - loss: 0.4374 - acc: 0.802 - ETA: 0s - loss: 0.4315 - acc: 0.805 - ETA: 0s - loss: 0.4351 - acc: 0.802 - ETA: 0s - loss: 0.4331 - acc: 0.797 - ETA: 0s - loss: 0.4285 - acc: 0.800 - ETA: 0s - loss: 0.4370 - acc: 0.798 - ETA: 0s - loss: 0.4365 - acc: 0.800 - ETA: 0s - loss: 0.4449 - acc: 0.791 - ETA: 0s - loss: 0.4451 - acc: 0.790 - 1s 2ms/step - loss: 0.4473 - acc: 0.7883 - val_loss: 0.4673 - val_acc: 0.7727\n",
      "Epoch 70/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4968 - acc: 0.800 - ETA: 0s - loss: 0.4516 - acc: 0.760 - ETA: 0s - loss: 0.4624 - acc: 0.787 - ETA: 0s - loss: 0.4277 - acc: 0.800 - ETA: 0s - loss: 0.4163 - acc: 0.821 - ETA: 0s - loss: 0.4329 - acc: 0.805 - ETA: 0s - loss: 0.4249 - acc: 0.809 - ETA: 0s - loss: 0.4239 - acc: 0.812 - ETA: 0s - loss: 0.4279 - acc: 0.807 - ETA: 0s - loss: 0.4354 - acc: 0.800 - ETA: 0s - loss: 0.4310 - acc: 0.800 - ETA: 0s - loss: 0.4311 - acc: 0.800 - ETA: 0s - loss: 0.4460 - acc: 0.795 - ETA: 0s - loss: 0.4466 - acc: 0.793 - ETA: 0s - loss: 0.4444 - acc: 0.793 - ETA: 0s - loss: 0.4448 - acc: 0.788 - ETA: 0s - loss: 0.4380 - acc: 0.790 - ETA: 0s - loss: 0.4424 - acc: 0.792 - ETA: 0s - loss: 0.4505 - acc: 0.785 - 1s 2ms/step - loss: 0.4479 - acc: 0.7866 - val_loss: 0.4756 - val_acc: 0.7532\n",
      "Epoch 71/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4946 - acc: 0.700 - ETA: 0s - loss: 0.4115 - acc: 0.800 - ETA: 0s - loss: 0.4299 - acc: 0.814 - ETA: 0s - loss: 0.4601 - acc: 0.790 - ETA: 0s - loss: 0.4510 - acc: 0.792 - ETA: 0s - loss: 0.4613 - acc: 0.768 - ETA: 0s - loss: 0.4514 - acc: 0.778 - ETA: 0s - loss: 0.4504 - acc: 0.791 - ETA: 0s - loss: 0.4530 - acc: 0.788 - ETA: 0s - loss: 0.4654 - acc: 0.775 - ETA: 0s - loss: 0.4558 - acc: 0.784 - ETA: 0s - loss: 0.4509 - acc: 0.788 - ETA: 0s - loss: 0.4458 - acc: 0.792 - ETA: 0s - loss: 0.4473 - acc: 0.792 - ETA: 0s - loss: 0.4447 - acc: 0.795 - ETA: 0s - loss: 0.4635 - acc: 0.781 - ETA: 0s - loss: 0.4484 - acc: 0.792 - ETA: 0s - loss: 0.4467 - acc: 0.796 - ETA: 0s - loss: 0.4501 - acc: 0.793 - 1s 2ms/step - loss: 0.4498 - acc: 0.7932 - val_loss: 0.4659 - val_acc: 0.7727\n",
      "Epoch 72/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4910 - acc: 0.600 - ETA: 0s - loss: 0.3809 - acc: 0.820 - ETA: 0s - loss: 0.3788 - acc: 0.833 - ETA: 0s - loss: 0.4077 - acc: 0.825 - ETA: 0s - loss: 0.4280 - acc: 0.800 - ETA: 0s - loss: 0.4306 - acc: 0.805 - ETA: 0s - loss: 0.4238 - acc: 0.804 - ETA: 0s - loss: 0.4278 - acc: 0.804 - ETA: 0s - loss: 0.4412 - acc: 0.789 - ETA: 0s - loss: 0.4377 - acc: 0.796 - ETA: 0s - loss: 0.4441 - acc: 0.788 - ETA: 0s - loss: 0.4437 - acc: 0.792 - ETA: 0s - loss: 0.4359 - acc: 0.797 - ETA: 0s - loss: 0.4290 - acc: 0.800 - ETA: 0s - loss: 0.4365 - acc: 0.793 - ETA: 0s - loss: 0.4424 - acc: 0.794 - ETA: 0s - loss: 0.4490 - acc: 0.789 - ETA: 0s - loss: 0.4469 - acc: 0.791 - ETA: 0s - loss: 0.4477 - acc: 0.790 - 1s 2ms/step - loss: 0.4484 - acc: 0.7899 - val_loss: 0.4668 - val_acc: 0.7727\n",
      "Epoch 73/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.3544 - acc: 0.700 - ETA: 1s - loss: 0.4659 - acc: 0.700 - ETA: 1s - loss: 0.4223 - acc: 0.771 - ETA: 0s - loss: 0.4211 - acc: 0.781 - ETA: 0s - loss: 0.4418 - acc: 0.771 - ETA: 0s - loss: 0.4319 - acc: 0.783 - ETA: 0s - loss: 0.4627 - acc: 0.771 - ETA: 0s - loss: 0.4514 - acc: 0.779 - ETA: 0s - loss: 0.4505 - acc: 0.778 - ETA: 0s - loss: 0.4551 - acc: 0.787 - ETA: 0s - loss: 0.4672 - acc: 0.782 - ETA: 0s - loss: 0.4591 - acc: 0.786 - ETA: 0s - loss: 0.4589 - acc: 0.790 - ETA: 0s - loss: 0.4542 - acc: 0.790 - ETA: 0s - loss: 0.4543 - acc: 0.791 - ETA: 0s - loss: 0.4518 - acc: 0.792 - ETA: 0s - loss: 0.4466 - acc: 0.796 - ETA: 0s - loss: 0.4469 - acc: 0.798 - ETA: 0s - loss: 0.4481 - acc: 0.798 - 1s 2ms/step - loss: 0.4452 - acc: 0.7980 - val_loss: 0.4748 - val_acc: 0.7662\n",
      "Epoch 74/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4883 - acc: 0.700 - ETA: 0s - loss: 0.3684 - acc: 0.800 - ETA: 0s - loss: 0.3846 - acc: 0.800 - ETA: 0s - loss: 0.4310 - acc: 0.772 - ETA: 0s - loss: 0.4364 - acc: 0.766 - ETA: 0s - loss: 0.4299 - acc: 0.768 - ETA: 0s - loss: 0.4418 - acc: 0.772 - ETA: 0s - loss: 0.4436 - acc: 0.773 - ETA: 0s - loss: 0.4463 - acc: 0.766 - ETA: 0s - loss: 0.4397 - acc: 0.775 - ETA: 0s - loss: 0.4387 - acc: 0.777 - ETA: 0s - loss: 0.4360 - acc: 0.782 - ETA: 0s - loss: 0.4359 - acc: 0.788 - ETA: 0s - loss: 0.4454 - acc: 0.780 - ETA: 0s - loss: 0.4482 - acc: 0.782 - ETA: 0s - loss: 0.4469 - acc: 0.783 - ETA: 0s - loss: 0.4517 - acc: 0.780 - ETA: 0s - loss: 0.4481 - acc: 0.785 - 1s 2ms/step - loss: 0.4458 - acc: 0.7866 - val_loss: 0.4714 - val_acc: 0.7792\n",
      "Epoch 75/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3984 - acc: 0.800 - ETA: 0s - loss: 0.3404 - acc: 0.920 - ETA: 0s - loss: 0.4053 - acc: 0.833 - ETA: 0s - loss: 0.3862 - acc: 0.841 - ETA: 0s - loss: 0.4248 - acc: 0.800 - ETA: 0s - loss: 0.4343 - acc: 0.800 - ETA: 0s - loss: 0.4351 - acc: 0.795 - ETA: 0s - loss: 0.4304 - acc: 0.800 - ETA: 0s - loss: 0.4573 - acc: 0.781 - ETA: 0s - loss: 0.4492 - acc: 0.790 - ETA: 0s - loss: 0.4536 - acc: 0.782 - ETA: 0s - loss: 0.4619 - acc: 0.775 - ETA: 0s - loss: 0.4548 - acc: 0.785 - ETA: 0s - loss: 0.4728 - acc: 0.772 - ETA: 0s - loss: 0.4671 - acc: 0.778 - ETA: 0s - loss: 0.4644 - acc: 0.778 - ETA: 0s - loss: 0.4519 - acc: 0.787 - ETA: 0s - loss: 0.4421 - acc: 0.794 - ETA: 0s - loss: 0.4446 - acc: 0.790 - 1s 2ms/step - loss: 0.4467 - acc: 0.7866 - val_loss: 0.4684 - val_acc: 0.7857\n",
      "Epoch 76/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.5859 - acc: 0.600 - ETA: 0s - loss: 0.5401 - acc: 0.660 - ETA: 0s - loss: 0.5784 - acc: 0.687 - ETA: 0s - loss: 0.5106 - acc: 0.758 - ETA: 0s - loss: 0.5029 - acc: 0.737 - ETA: 0s - loss: 0.4925 - acc: 0.745 - ETA: 0s - loss: 0.4938 - acc: 0.747 - ETA: 0s - loss: 0.4693 - acc: 0.765 - ETA: 0s - loss: 0.4584 - acc: 0.775 - ETA: 0s - loss: 0.4592 - acc: 0.775 - ETA: 0s - loss: 0.4623 - acc: 0.780 - ETA: 0s - loss: 0.4547 - acc: 0.784 - ETA: 0s - loss: 0.4554 - acc: 0.785 - ETA: 0s - loss: 0.4451 - acc: 0.793 - ETA: 0s - loss: 0.4388 - acc: 0.795 - ETA: 0s - loss: 0.4373 - acc: 0.794 - ETA: 0s - loss: 0.4379 - acc: 0.794 - ETA: 0s - loss: 0.4440 - acc: 0.790 - 1s 2ms/step - loss: 0.4442 - acc: 0.7915 - val_loss: 0.4686 - val_acc: 0.7792\n",
      "Epoch 77/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.2505 - acc: 1.000 - ETA: 0s - loss: 0.5704 - acc: 0.760 - ETA: 0s - loss: 0.4895 - acc: 0.800 - ETA: 0s - loss: 0.4714 - acc: 0.781 - ETA: 0s - loss: 0.4441 - acc: 0.800 - ETA: 0s - loss: 0.4424 - acc: 0.800 - ETA: 0s - loss: 0.4360 - acc: 0.810 - ETA: 0s - loss: 0.4220 - acc: 0.804 - ETA: 0s - loss: 0.4063 - acc: 0.820 - ETA: 0s - loss: 0.3944 - acc: 0.829 - ETA: 0s - loss: 0.4119 - acc: 0.813 - ETA: 0s - loss: 0.4231 - acc: 0.809 - ETA: 0s - loss: 0.4244 - acc: 0.811 - ETA: 0s - loss: 0.4250 - acc: 0.812 - ETA: 0s - loss: 0.4224 - acc: 0.809 - ETA: 0s - loss: 0.4313 - acc: 0.804 - ETA: 0s - loss: 0.4375 - acc: 0.793 - ETA: 0s - loss: 0.4432 - acc: 0.788 - ETA: 0s - loss: 0.4345 - acc: 0.794 - ETA: 0s - loss: 0.4413 - acc: 0.791 - ETA: 0s - loss: 0.4438 - acc: 0.791 - 1s 2ms/step - loss: 0.4452 - acc: 0.7899 - val_loss: 0.4703 - val_acc: 0.7792\n",
      "Epoch 78/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3794 - acc: 0.800 - ETA: 1s - loss: 0.3561 - acc: 0.850 - ETA: 0s - loss: 0.3944 - acc: 0.828 - ETA: 0s - loss: 0.4026 - acc: 0.810 - ETA: 0s - loss: 0.4025 - acc: 0.816 - ETA: 0s - loss: 0.4190 - acc: 0.787 - ETA: 0s - loss: 0.3995 - acc: 0.800 - ETA: 0s - loss: 0.4486 - acc: 0.777 - ETA: 0s - loss: 0.4481 - acc: 0.780 - ETA: 0s - loss: 0.4441 - acc: 0.782 - ETA: 0s - loss: 0.4554 - acc: 0.781 - ETA: 0s - loss: 0.4479 - acc: 0.786 - ETA: 0s - loss: 0.4501 - acc: 0.790 - ETA: 0s - loss: 0.4479 - acc: 0.788 - ETA: 0s - loss: 0.4494 - acc: 0.787 - ETA: 0s - loss: 0.4460 - acc: 0.790 - ETA: 0s - loss: 0.4476 - acc: 0.790 - ETA: 0s - loss: 0.4457 - acc: 0.789 - 1s 2ms/step - loss: 0.4425 - acc: 0.7915 - val_loss: 0.4683 - val_acc: 0.7727\n",
      "Epoch 79/80\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3417 - acc: 0.900 - ETA: 0s - loss: 0.5353 - acc: 0.760 - ETA: 0s - loss: 0.4672 - acc: 0.787 - ETA: 0s - loss: 0.4759 - acc: 0.800 - ETA: 0s - loss: 0.4647 - acc: 0.780 - ETA: 0s - loss: 0.4681 - acc: 0.766 - ETA: 0s - loss: 0.4502 - acc: 0.777 - ETA: 0s - loss: 0.4591 - acc: 0.760 - ETA: 0s - loss: 0.4511 - acc: 0.767 - ETA: 0s - loss: 0.4409 - acc: 0.777 - ETA: 0s - loss: 0.4297 - acc: 0.785 - ETA: 0s - loss: 0.4332 - acc: 0.784 - ETA: 0s - loss: 0.4357 - acc: 0.785 - ETA: 0s - loss: 0.4479 - acc: 0.780 - ETA: 0s - loss: 0.4513 - acc: 0.780 - ETA: 0s - loss: 0.4492 - acc: 0.786 - ETA: 0s - loss: 0.4467 - acc: 0.784 - ETA: 0s - loss: 0.4469 - acc: 0.787 - ETA: 0s - loss: 0.4374 - acc: 0.794 - 1s 2ms/step - loss: 0.4446 - acc: 0.7899 - val_loss: 0.4704 - val_acc: 0.7857\n",
      "Epoch 80/80\n",
      "614/614 [==============================] - ETA: 1s - loss: 0.4787 - acc: 0.700 - ETA: 1s - loss: 0.4685 - acc: 0.775 - ETA: 1s - loss: 0.5045 - acc: 0.757 - ETA: 0s - loss: 0.5397 - acc: 0.740 - ETA: 0s - loss: 0.5154 - acc: 0.746 - ETA: 0s - loss: 0.4777 - acc: 0.775 - ETA: 0s - loss: 0.4719 - acc: 0.778 - ETA: 0s - loss: 0.4639 - acc: 0.782 - ETA: 0s - loss: 0.4612 - acc: 0.784 - ETA: 0s - loss: 0.4499 - acc: 0.793 - ETA: 0s - loss: 0.4369 - acc: 0.803 - ETA: 0s - loss: 0.4323 - acc: 0.802 - ETA: 0s - loss: 0.4319 - acc: 0.800 - ETA: 0s - loss: 0.4306 - acc: 0.800 - ETA: 0s - loss: 0.4290 - acc: 0.804 - ETA: 0s - loss: 0.4450 - acc: 0.790 - ETA: 0s - loss: 0.4490 - acc: 0.786 - ETA: 0s - loss: 0.4489 - acc: 0.786 - ETA: 0s - loss: 0.4468 - acc: 0.786 - 1s 2ms/step - loss: 0.4435 - acc: 0.7915 - val_loss: 0.4669 - val_acc: 0.7662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26be7e30908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.2, epochs=80, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save NN model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = 'VHDL_model_example/model.h5'\n",
    "model.save(modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's generate VHDL code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer generation function\n",
    "<img src=\"images/pic1.png\">\n",
    "config - JSON layer description\n",
    "\n",
    "weights - weights and bias of layer\n",
    "\n",
    "sequential - generate parallel or sequential code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Dense(config, weights, sequential = False):\n",
    "    VHDL_code = ''\n",
    "    W = weights[0]\n",
    "    b = weights[1]\n",
    "    neurons = len(W[0])\n",
    "    inputs = len(W)\n",
    "    #includs\n",
    "    VHDL_code += 'use work.activations.all;\\n'\n",
    "    VHDL_code += 'use work.datatypes.all;\\n'\n",
    "    VHDL_code += 'library IEEE;\\n'\n",
    "    VHDL_code += 'use IEEE.MATH_REAL.ALL;\\n\\n'\n",
    "    #generate entity\n",
    "    VHDL_code += 'entity %s is\\n' % (config['name'])\n",
    "    VHDL_code += 'port(\\n'\n",
    "    VHDL_code += '\\tinput: in Vector(0 to %d):=(others=>0.0);\\n' % (inputs-1)\n",
    "    VHDL_code += '\\tNeuron: out Vector(0 to %d):=(others=>0.0)\\n' % (neurons-1)\n",
    "    VHDL_code += ');\\n'\n",
    "    VHDL_code += 'end %s;\\n\\n' % (config['name'])\n",
    "    VHDL_code += 'architecture struct of %s is\\n\\n' % (config['name'])\n",
    "    #generate weights description\n",
    "    for i in range(inputs):\n",
    "        VHDL_code += 'constant W%d: Vector(0 to %d) := (' % (i,neurons-1)\n",
    "        for j in range(neurons):\n",
    "            VHDL_code += str(W[i][j]) + ','\n",
    "        if neurons == 1:\n",
    "            VHDL_code += ' others => 0.0,'\n",
    "        VHDL_code = VHDL_code[:-1] + ');\\n'\n",
    "    VHDL_code += 'constant b: Vector(0 to %d) := (' % (neurons-1)\n",
    "    for i in range(neurons):\n",
    "        VHDL_code += str(b[i]) + ','\n",
    "    if neurons == 1:\n",
    "        VHDL_code += ' others => 0.0,'    \n",
    "    VHDL_code = VHDL_code[:-1] + ');\\n'\n",
    "    VHDL_code += '\\nbegin\\n'\n",
    "    #generate computation\n",
    "    for i in range(neurons):\n",
    "        VHDL_code += '\\tNeuron(%d) <= %s(' % (i,config['activation'] if config['activation']!= 'softmax' else '')\n",
    "        if not sequential:\n",
    "            for j in range(inputs):\n",
    "                VHDL_code += '(input(%d)*W%d(%d))+' % (j,j,i)\n",
    "        else:\n",
    "            VHDL_code += 'serial_Vectormul(input,W)'\n",
    "        VHDL_code += 'b(%d));\\n' % (i)\n",
    "    #end    \n",
    "    VHDL_code += 'end struct;'\n",
    "    \n",
    "    return VHDL_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model description code\n",
    "<img src=\"images/pic2.png\">\n",
    "config - JSON array with layers description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TopLevel(config):\n",
    "    VHDL_code = ''\n",
    "    layers_count = len(config)\n",
    "    inputs_size = config[0]['config']['batch_input_shape'][1]\n",
    "    output_size = config[layers_count-1]['config']['units']\n",
    "    softmax = config[layers_count-1]['config']['activation'] == 'softmax'\n",
    "    #includs\n",
    "    VHDL_code += 'use work.activations.all;'\n",
    "    VHDL_code += 'use work.datatypes.all;\\n'\n",
    "    VHDL_code += 'library IEEE;\\n'\n",
    "    VHDL_code += 'use IEEE.MATH_REAL.ALL;\\n\\n'\n",
    "    #entity\n",
    "    VHDL_code += 'entity model is\\n'\n",
    "    VHDL_code += 'port(\\n'\n",
    "    VHDL_code += '\\tinput: in Vector(0 to %d);\\n' % (inputs_size-1)\n",
    "    VHDL_code += '\\toutput: out Vector(0 to %d)\\n' % (output_size-1)\n",
    "    VHDL_code += ');\\n'\n",
    "    VHDL_code += 'end model;\\n\\n'\n",
    "    VHDL_code += 'architecture struct of model is\\n\\n'\n",
    "    #components description\n",
    "    for i in range(layers_count):\n",
    "        config_layer = config[i]['config']\n",
    "        output_size = config_layer['units']\n",
    "        VHDL_code += 'component %s\\n' % (config_layer['name'])\n",
    "        VHDL_code += '\\tport('\n",
    "        VHDL_code += 'input: in Vector(0 to %d);' % (inputs_size-1)\n",
    "        VHDL_code += 'Neuron: out Vector(0 to %d)' % (output_size-1)\n",
    "        VHDL_code += ');\\n'\n",
    "        VHDL_code += 'end component;\\n'\n",
    "        inputs_size = output_size\n",
    "    #signals\n",
    "    VHDL_code += '\\n'\n",
    "    for i in range(layers_count-1):\n",
    "        VHDL_code += 'signal f%d: Vector(0 to %d);\\n' % (i+1, config[i]['config']['units']-1)\n",
    "    if softmax:\n",
    "        VHDL_code += 'signal f_sm: Vector(0 to %d);\\n' % (config[layers_count-2]['config']['units']-1)\n",
    "    #port map\n",
    "    VHDL_code += 'begin\\n'\n",
    "    VHDL_code += 'layer0: %s port map(input, f1);\\n' % (config[0]['config']['name'])\n",
    "    for i in range(1,layers_count-1):\n",
    "        VHDL_code += 'layer%d: %s port map(f%d, f%d);\\n' % (i, config[i]['config']['name'],i,i+1)\n",
    "    if softmax:\n",
    "        VHDL_code += 'layer%d: %s port map(f%d, f_sm);\\n' % (layers_count-1, config[layers_count-1]['config']['name'], layers_count-1)\n",
    "        VHDL_code += 'output <= softmax(f_sm)\\n'\n",
    "    else:\n",
    "        VHDL_code += 'layer%d: %s port map(f%d, output);\\n' % (layers_count-1, config[layers_count-1]['config']['name'], layers_count-1)\n",
    "    VHDL_code += 'end struct;'\n",
    "    return VHDL_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test description\n",
    "config - JSON array with layers description\n",
    "\n",
    "test_file - file with test data name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Test(config,test_file):\n",
    "    VHDL_code = ''\n",
    "    layers_count = len(config)\n",
    "    inputs_size = config[0]['config']['batch_input_shape'][1]\n",
    "    output_size = config[layers_count-1]['config']['units']\n",
    "    #includs\n",
    "    VHDL_code += 'use work.datatypes.all;\\n'\n",
    "    VHDL_code += 'library IEEE;\\n'\n",
    "    VHDL_code += 'use IEEE.MATH_REAL.ALL;\\n\\n'\n",
    "    VHDL_code += 'library std;\\n'\n",
    "    VHDL_code += 'use std.textio.all;\\n'\n",
    "    #entity\n",
    "    VHDL_code += 'entity test is\\n'\n",
    "    VHDL_code += 'end test;\\n\\n'\n",
    "    VHDL_code += 'architecture struct of test is\\n\\n'\n",
    "    #signals\n",
    "    VHDL_code += 'signal inputSet: Vector(0 to %d):=(others=>0.0);\\n' % (inputs_size-1)\n",
    "    VHDL_code += 'signal outputSet: Vector(0 to %d);\\n' % (output_size-1)\n",
    "    #component description\n",
    "    VHDL_code += 'component model\\n'\n",
    "    VHDL_code += 'port(\\n'\n",
    "    VHDL_code += '\\tinput: in Vector(0 to %d);\\n' % (inputs_size-1)\n",
    "    VHDL_code += '\\toutput: out Vector(0 to %d)\\n' % (output_size-1)\n",
    "    VHDL_code += ');\\n'\n",
    "    VHDL_code += 'end component;\\n'\n",
    "    #port map\n",
    "    VHDL_code += 'begin\\n'\n",
    "    VHDL_code += '\\tNN0: model port map(inputSet, outputSet);\\n\\n'\n",
    "    VHDL_code += '\\tprocess\\n'\n",
    "    VHDL_code += '\\t\\tfile file_r : text;\\n'\n",
    "    VHDL_code += '\\t\\tvariable line_var : line;\\n'\n",
    "    VHDL_code += '\\t\\tvariable inval : REAL;\\n'\n",
    "    \n",
    "    VHDL_code += '\\tbegin\\n'\n",
    "    VHDL_code += '\\t\\tfile_open(file_r, \"%s\",  read_mode);\\n' % (test_file)\n",
    "    VHDL_code += '\\t\\twhile(NOT ENDFILE(file_r)) loop\\n'\n",
    "    VHDL_code += '\\t\\t\\treadline(file_r,line_var);\\n'\n",
    "    VHDL_code += '\\t\\t\\tfor i in 0 to %d loop\\n' % (inputs_size-1)\n",
    "    VHDL_code += '\\t\\t\\t\\tread(line_var, inval);\\n'\n",
    "    VHDL_code += '\\t\\t\\t\\tinputSet(i) <= inval;\\n'\n",
    "    VHDL_code += '\\t\\t\\tend loop;\\n'\n",
    "    VHDL_code += '\\t\\t\\twait for 100 ns;\\n'\n",
    "    VHDL_code += '\\t\\tend loop;\\n'\n",
    "    VHDL_code += '\\t\\tfile_close(file_r);\\n'\n",
    "    VHDL_code += '\\t\\twait;\\n'\n",
    "    VHDL_code += '\\tend process;\\n'\n",
    "    \n",
    "    VHDL_code += 'end struct;'\n",
    "    return VHDL_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse model and generate and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:00<00:00, 15.03it/s]\n"
     ]
    }
   ],
   "source": [
    "modelfile = 'VHDL_model_example/model.h5'\n",
    "model = load_model(modelfile)\n",
    "for i in tqdm(range(len(model.layers))):\n",
    "    layer = model.layers[i]\n",
    "    config = model.get_config()[i]\n",
    "    weights = layer.get_weights()\n",
    "    if config['class_name'] == 'Dense':\n",
    "        VHDL_code = generate_Dense(config['config'], weights)\n",
    "    else:\n",
    "        print('Unknown layer type %s' % config['class_name'])\n",
    "    with open('VHDL_model_example/'+config['config']['name']+'.vhd', 'w') as file:\n",
    "        file.write(VHDL_code)\n",
    "VHDL_code = generate_TopLevel(model.get_config())\n",
    "with open('VHDL_model_example/model.vhd', 'w') as file:\n",
    "    file.write(VHDL_code)\n",
    "with open('VHDL_model_example/test.vhd', 'w') as file:\n",
    "    file.write(generate_Test(model.get_config(), \"input.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=''\n",
    "for d in X[0:5]:\n",
    "    for n in d:\n",
    "        s += str(n)+' '\n",
    "    s+='\\n'\n",
    "with open('input.txt', 'w') as the_file:\n",
    "    the_file.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction with Python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.747935  ]\n",
      " [0.04691245]\n",
      " [0.84815276]\n",
      " [0.0367014 ]\n",
      " [0.86570984]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model(modelfile)\n",
    "print(model.predict(X[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ompare with the result of the VHDL model\n",
    "<img src=\"images/chart.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
